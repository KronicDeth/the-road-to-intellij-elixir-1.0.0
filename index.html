<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>ElixirConf 2015 - The Road to IntelliJ Elixir 1.0.0</title>

		<meta name="description" content="How I went from &quot;I wonder if there's an Rubymine plugin for Elixir?&quot; to writing one myself and eventually using it to find bugs in native Elixir.">
		<meta name="author" content="Luke Imhoff">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section class="stack">
					<section>
						<h1>ElixirConf 2015</h1>
						<h2>The Road to IntelliJ Elixir 1.0.0</h2>
						<p>2015-10-02 to 2015-10-03</p>
						<p>Luke Imhoff</p>
						<table>
							<tbody>
							<tr>
								<th>
									<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
                                     version="1.1" id="Capa_1" x="0px" y="0px" width="14px" height="10px"
                                     viewBox="0 0 14 10" enable-background="new 0 0 14 10" xml:space="preserve">
                                     <g>
                                        <path d="M7,7L5.268,5.484L0.316,9.729C0.496,9.896,0.739,10,1.007,10h11.986c0.267,0,0.509-0.104,0.688-0.271L8.732,5.484L7,7z"></path>
                                        <path d="M13.684,0.271C13.504,0.103,13.262,0,12.993,0H1.007C0.74,0,0.498,0.104,0.318,0.273L7,6L13.684,0.271z"></path>
                                        <polygon points="0,0.878 0,9.186 4.833,5.079  "></polygon>
                                        <polygon points="9.167,5.079 14,9.186 14,0.875  "></polygon>
                                     </g>
                                </svg>
								</th>
								<td>Kronic.Deth@gmail.com</td>
							</tr>
							<tr>
								<th>
									<svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg"
                                     xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16"
                                     enable-background="new 0 0 16 16" xml:space="preserve">
                                            <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"></path>
                               </svg>
								</th>
								<td>
									<a href="https://github.com/KronicDeth" target="_blank">@KronicDeth</a>
								</td>
							</tr>
							<tr>
								<th>
									<svg version="1.1" class="twitter-icon-svg"
                                            xmlns="http://www.w3.org/2000/svg"
                                            xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                                            <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"></path>
                                        </svg>
								</th>
								<td>
									<a href="https://twitter.com/KronicDeth" target="_blank">@KronicDeth</a>
								</td>
							</tr>
							</tbody>
						</table>
						<aside class="notes">
							<p>
								I am the maintainer of intellij-elixir, the Elixir plugin for Jetbrains IDEs.  I have
								contributed to the Elixir standard library and found bugs in the native tokenizer and parser
								through my work on intellij-elixir.  I help run the Austin Elixir meetup.
							</p>
						</aside>
					</section>
					<section>
						<h1>This Presentation</h1>
						<dl>
							<dt>Slides</dt>
							<dd>
								<dl>
									<dt>Viewable</dt>
									<dd>
										<a href="https://kronicdeth.github.io/the-road-to-intellij-elixir-1.0.0">
											https://kronicdeth.github.io/the-road-to-intellij-elixir-1.0.0
										</a>
									</dd>
									<dt>Source</dt>
									<dd>
										<a href="https://github.com/KronicDeth/the-road-to-intellij-elixir-1.0.0/tree/gh-pages">
											https://github.com/KronicDeth/the-road-to-intellij-elixir-1.0.0/tree/gh-pages
										</a>
									</dd>
								</dl>
							</dd>
							<dt>Project Source</dt>
							<dd>
								<a href="https://github.com/KronicDeth/intellij-elixir/tree/v1.0.0">
									https://github.com/KronicDeth/intellij-elixir/tree/v1.0.0
								</a>
							</dd>
						</dl>
						<aside class="notes">
							<p>
								For viewers that want to follow along with their own copy of the slides or project
								source, they can be accessed at the shown addresses.
							</p>
						</aside>
					</section>
					<section>
						<h1>Outline</h1>
						<ul>
							<li>
								<a href="#/introduction">Introduction</a>
							</li>
							<li>
								<a href="#/bnf">BNF</a>
							</li>
							<li>
								<a href="#/syntax">Syntax</a>
							</li>
                            <li>
                                <a href="#/interpolation">Interpolation</a>
                            </li>
                            <li>
                                <a href="#/sigils">Sigils</a>
                            </li>
                            <li>
                                <a href="#/atoms">Atoms</a>
                            </li>
							<li>
								<a href="#/matched-expressions">Matched Expressions</a>
							</li>
						</ul>
					</section>
				</section>
				<section class="stack">
					<section id="introduction">
						<h1>Introduction</h1>
						<ul>
							<li>
								<a href="#/introduction-why-an-intellij-plugin">
									Why an IntelliJ Plugin?
								</a>
							</li>
							<li>
								<a href="#/introduction-timeline">
									Timeline
								</a>
							</li>
						</ul>
					</section>
					<section id="introduction-why-an-intellij-plugin">
						<h1>Why an IntelliJ Plugin?</h1>
						<ul>
							<li>I use Rubymine for Ruby development</li>
							<li>Wanted vim key bindings</li>
							<li>Wanted Cmd+Click Go To Definition for Elixir</li>
							<li>Wanted Search Everywhere for Elixir</li>
							<li>There was a tutorial</li>
						</ul>
						<aside class="notes">
							<p>
								People may wonder why I took it upon myself to make an IDE plugin for Elixir, when I
								could have used a vim or emacs plugin.
							</p>
							<p>
								I've used both emacs and vim.  I started with emacs when I worked at Cray, only
								switching to vim when I needed something that worked over a high-latency, low-bandwidth
								CDMA modem on the high-way.
							</p>
							<p>
								I started using Rubymine when my boss at a previous job, Nicholas Cancelliere,
								introduced me to it.  I was shocked that an IDE for a dynamic language like Ruby could
								support Find Usage, Go To Definition, and Refactor.  I had been use to using ctags for
								vim.
							</p>
							<p>
								I haven't complete abandoned using vim either.  I still use syntax highlighting plugins
								for vim in iTerm when I need to edit configuration files and I use the IDEAVim plugin
								for Jetbrains IDEs like Rubymine, Webstorm, and IntelliJ.
							</p>
							<p>
								Without Rubymine I don't think I'd have been able to as quickly dive through the complex
								code-base in Metasploit and the graphical debugger allowed me to teach myself the
								internals of Rails and other DSLs.
							</p>
							<p>
								I understood that many of the features I liked about Rubymine were shared across
								JetBrains' various IDEs, so if I could write the parts of a plugin to get JetBrains APIs
								to understand Elixir syntax and semantics, the features I really wanted would just work
								without me having to understand how to write the parts that were cross-language.
							</p>
							<p>
								However, just getting syntax lexing and parsing right ended up taking a year...
							</p>
						</aside>
					</section>
					<section id="introduction-timeline">
						<h1>Timeline</h1>
						<table style="font-size: 85%">
							<thead>
							<tr>
								<th rowspan="2">Date</th>
								<th colspan="2">Days</th>
								<th colspan="2">Commits</th>
								<th colspan="2">Version</th>
							</tr>
							<tr>
								<th>Delta</th>
								<th>Total</th>
								<th>Delta</th>
								<th>Total</th>
								<th>Commits/Day</th>
								<th>Name</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<td>2014-07-27</td>
								<td>0</td>
								<td>0</td>
								<td>1</td>
								<td>1</td>
								<td>1.00</td>
								<td>Initial</td>
							</tr>
							<tr>
								<td>2014&#8209;08&#8209;02</td>
								<td>6</td>
								<td>6</td>
								<td>18</td>
								<td>19</td>
								<td>3.00</td>
								<td>0.0.1</td>
							</tr>
							<tr>
								<td>2014&#8209;08&#8209;03</td>
								<td>1</td>
								<td>7</td>
								<td>14</td>
								<td>33</td>
								<td>14.00</td>
								<td>0.0.2</td>
							</tr>
							<tr>
								<td>2014&#8209;08&#8209;08</td>
								<td>5</td>
								<td>12</td>
								<td>10</td>
								<td>43</td>
								<td>2.00</td>
								<td>0.0.3</td>
							</tr>
							<tr>
								<td>2014&#8209;09&#8209;13</td>
								<td>36</td>
								<td>48</td>
								<td>64</td>
								<td>107</td>
								<td>1.78</td>
								<td>0.1.0</td>
							</tr>
							<tr>
								<td>2014&#8209;09&#8209;20</td>
								<td>7</td>
								<td>55</td>
								<td>4</td>
								<td>111</td>
								<td>0.57</td>
								<td>0.1.1</td>
							</tr>
							<tr>
								<td>2014&#8209;09&#8209;25</td>
								<td>5</td>
								<td>60</td>
								<td>12</td>
								<td>123</td>
								<td>2.50</td>
								<td>0.1.2</td>
							</tr>
							<tr>
								<td>2014&#8209;10&#8209;14</td>
								<td>19</td>
								<td>79</td>
								<td>23</td>
								<td>146</td>
								<td>1.21</td>
								<td>0.1.3</td>
							</tr>
							<tr>
								<td>2014&#8209;11&#8209;30</td>
								<td>47</td>
								<td>126</td>
								<td>226</td>
								<td>373</td>
								<td>4.81</td>
								<td>0.2.0</td>
							</tr>
							<tr>
								<td>2015&#8209;04&#8209;03</td>
								<td>124</td>
								<td>250</td>
								<td>521</td>
								<td>894</td>
								<td>4.20</td>
								<td>0.2.1</td>
							</tr>
							<tr>
								<td>2015&#8209;04&#8209;10</td>
								<td>7</td>
								<td>257</td>
								<td>27</td>
								<td>921</td>
								<td>3.86</td>
								<td>0.3.0</td>
							</tr>
							<tr>
								<td>2015&#8209;04&#8209;27</td>
								<td>17</td>
								<td>274</td>
								<td>66</td>
								<td>987</td>
								<td>3.88</td>
								<td>0.3.1</td>
							</tr>
							<tr>
								<td>2015&#8209;05&#8209;01</td>
								<td>4</td>
								<td>278</td>
								<td>8</td>
								<td>995</td>
								<td>2.00</td>
								<td>0.3.2</td>
							</tr>
							<tr>
								<td>2015&#8209;05&#8209;15</td>
								<td>14</td>
								<td>292</td>
								<td>34</td>
								<td>1029</td>
								<td>2.43</td>
								<td>0.3.3</td>
							</tr>
							<tr>
								<td>2015&#8209;06&#8209;04</td>
								<td>20</td>
								<td>312</td>
								<td>86</td>
								<td>1115</td>
								<td>4.30</td>
								<td>0.3.4</td>
							</tr>
							<tr>
								<td>2015&#8209;07&#8209;08</td>
								<td>34</td>
								<td>346</td>
								<td>83</td>
								<td>1198</td>
								<td>2.44</td>
								<td>0.3.5</td>
							</tr>
							<tr>
								<td>2015&#8209;07&#8209;27</td>
								<td>19</td>
								<td>365</td>
								<td>158</td>
								<td>1356</td>
								<td>2.44</td>
								<td>1.0.0</td>
							</tr>
							</tbody>
						</table>
						<aside class="notes">
							<p>
								I was exactly 1 year between the initial commit of the project skeleton to the v1.0.0 tag.
							</p>
						</aside>
					</section>
				</section>
				<section class="stack">
					<section id="bnf">
						<h1>BNF</h1>
						<ul>
							<li>
								<a href="#/bnf-backus-naur-form">Backus Naur Form</a>
							</li>
							<li>
								<a href="#/bnf-yecc">YECC</a>
							</li>
							<li>
								<a href="#/bnf-grammar-kit">Grammar Kit</a>
							</li>
							<li>
								<a href="#/bnf-v0.0.1">v0.0.1</a>
							</li>
						</ul>
					</section>
					<section id="bnf-backus-naur-form">
						<h1>Backus-Naur Form</h1>
						<table>
							<thead>
							<tr>
								<th>Read as</th>
								<th>Symbol</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<td>Metasyntactic Variable</td>
								<td>
									<pre><code class="bnf">&lt;variable&gt;</code></pre>
								</td>
							</tr>
							<tr>
								<td>is defined as</td>
								<td>
									<pre><code class="bnf">::=</code></pre>
								</td>
							</tr>
							<tr>
								<td>or</td>
								<td>
									<pre><code class="bnf">|</code></pre>
								</td>
							</tr>
							</tbody>
						</table>
						<pre><code data-trim>
&lt;expr&gt; ::= &lt;integer&gt; | &lt;expr&gt; &lt;op&gt; &lt;integer&gt;
						</code></pre>
						<aside class="notes">
							<p>
								One of the standard ways of defining a syntax is in BNF, or Backus-Naur Form, which
								was first used for the Algol 60 standard.
							</p>
							<p>
								Both YECC and GrammarKit use a form of BNF, so I assumed it was just a matter of
								porting elixir dot Y-R-L to elixir dot B-N-F.
							</p>
						</aside>
					</section>
					<section id="bnf-yecc">
						<h1>YECC</h1>
						<figure>
							<figcaption>
								<a href="https://github.com/elixir-lang/elixir/blob/12f89a30b46279398fc7143e433681c2194b03d9/lib/elixir/src/elixir_parser.yrl#L77-L82">
									lib/elixir/src/elixir_parser.yrl
								</a>
							</figcaption>
							<pre><code data-trim style="font-size: 300%; line-height: 100%">
grammar -> eoe : nil.
grammar -> expr_list : to_block('$1').
grammar -> eoe expr_list : to_block('$2').
grammar -> expr_list eoe : to_block('$1').
grammar -> eoe expr_list eoe : to_block('$2').
grammar -> '$empty' : nil.
							</code></pre>
						</figure>
						<aside class="notes">
							<p>
								YECC is a parser generator written in Erlang (and part of the standard distribution)
								that is based on yacc (with an 'a' instead of an 'e'), which is a parser generator
								written in C.
							</p>
							<p>
								The YECC syntax differs from B-N-F in that it uses a skinny arrow (<code>-></code>)
								instead of colon colon equals (<code>::=</code>) and instead of using pipe
								(<code>|</code>) for OR, lines with the same rule name are repeated with alternative
								definitions. Finally, YECC supports running Erlang code on the tokens using dollar
								number (<code>$n</code>) for positional references to the matches tokens.
							</p>
							<p>
								dollar empty (<code>$empty</code>) is a special token that matches no input.  In
								formal grammars this is usually referred to as (lowercase) epsilon (<code>ɛ</code>).
							</p>
						</aside>
					</section>
					<section id="bnf-grammar-kit">
						<h1>Grammar Kit</h1>
						<figure>
							<figcaption>
								<a href="https://github.com/KronicDeth/intellij-elixir/blob/v1.0.0/src/org/elixir_lang/Elixir.bnf">
									src/org/elixir_lang/Elixir.bnf
								</a>
							</figcaption>
							<pre><code data-trim style="font-size: 165%; line-height: 100%">
private elixirFile ::= endOfExpression? (expressionList endOfExpression?)?
private expressionList ::= expression (endOfExpression expression | adjacentExpression)*
							</code></pre>
						</figure>
						<aside class="notes">
							<p>
								Grammar Kit is a parser generator written in Java and created by JetBrains.
							</p>
							<p>
								GrammarKit's B-N-F format <strong>does</strong> use colon colon equals (<code>::=</code>)
								like Backus-Naur Form, but it has some more power constructs above pipe (<code>|</code>)
								for OR.
							</p>
							<p>
								Question mark (<code>?</code>) can be used for 0 or 1, parentheses (<code>()</code>)
								can be used for grouping; and star can be used for 0 or more.  Empty can be implied
								by question mark (<code>?</code>) or star (<code>*</code>) matching nothing or there
								being nothing on the right-hand-side of the colon colon equals (<code>::=</code>).
							</p>
							<p>
								You'll also notice that there is no inline Java code after the rule definition unlike
								in YECC where there as Erlang code.  This is because GrammarKit automatically generates
								an AST, which it calls a PSI (or Program Structure Interface) Tree from the matched
								rules, so there's no need to define how to build the tree.
							</p>
							<p>
								Having GrammarKit generate the AST is both good and bad.  It's good because it removes
								a lot of redundant code, but it's bad because rules must evaluate in the correct order
								to reflect the desired nesting and associativity without any manual fixups, which are
								possible with the Erlang code in YECC.
							</p>
						</aside>
					</section>
					<section id="bnf-v0.0.1">
						<h1>v0.0.1</h1>
                        <table style="font-size: 85%">
							<thead>
							<tr>
								<th rowspan="2">Date</th>
								<th colspan="2">Days</th>
								<th colspan="2">Commits</th>
								<th colspan="2">Version</th>
							</tr>
							<tr>
								<th>Delta</th>
								<th>Total</th>
								<th>Delta</th>
								<th>Total</th>
								<th>Commits/Day</th>
							</tr>
							</thead>
							<tbody>
                            <tr>
								<td>2014&#8209;08&#8209;02</td>
								<td>6</td>
								<td>6</td>
								<td>18</td>
								<td>19</td>
								<td>3.00</td>
							</tr>
                            </tbody>
                        </table>
						<ol>
							<li>Translate from YECC to Grammar Kit</li>
							<li>Freeze IDE</li>
						</ol>
						<aside class="notes">
							<p>
								YECC and Grammar Kit both support a form of BNF and Grammar Kit seems like it would
								support even a more compact grammar because question mark (<code>?</code>), star
								(<code>star</code>), pipe (<code>|</code>) and parentheses (<code>()</code>) could
								eliminate some of the redundancy needed in the multi-clause rules in YECC.
							</p>
							<p>
								After only 6 days I had quote unquote translated the BNF from yecc to Grammar Kit and
								ended up with a parser that froze the IDE, which Julius "h4cc" Beckmann reported. That
								left the slow process of translating the grammar correctly over the next 359 days.  At
								the time of the freeze, I didn't even really understand translating the BNF didn't work,
								all I knew was I needed to go slower and build the grammar up from simpler, testable
								pieces.
							</p>
						</aside>
					</section>
				</section>
				<section class="stack">
					<section id="syntax">
						<h1>Syntax</h1>
						<ul>
							<li>
								<a href="#/syntax-analysis">Syntactic Analysis</a>
							</li>
							<li>
								<a href="#/syntax-lexing">Lexing/Tokenizing</a>
							</li>
                            <li>
                                <a href="#/syntax-ignored">Ignoring Characters</a>
                            </li>
                            <li>
                                <a href="#/syntax-base-integers">Base Integers</a>
                            </li>
							<li>
								<a href="#/syntax-jflex-lexer-generation">JFlex Lexer Generation</a>
							</li>
                            <li>
                                <a href="#/syntax-finite-automaton">Finite Automaton</a>
                            </li>
                            <li>
                                <a href="#/syntax-jflex-generated-lexer-packing">JFlex Generated Lexer - Packaing</a>
                            </li>
                            <li>
                                <a href="#/syntax-jflex-generated-lexer-switch">JFlex Generated Lexer - Switch</a>
                            </li>
							<li>
								<a href="#/syntax-v0.0.2">v0.0.2</a>
							</li>
						</ul>
					</section>
					<section id="syntax-analysis">
						<h1>Syntactic Analysis</h1>
						<table>
							<thead>
							<tr>
								<th>Step</th>
								<th>Elixir</th>
								<th>IntelliJ Elixir</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<th>Lexing</th>
								<td>
									Erlang
								</td>
								<td>
									JFlex
								</td>
							</tr>
							<tr>
								<th>Parsing</th>
								<td>
									YECC
								</td>
								<td>
									GrammarKit
								</td>
							</tr>
							</tbody>
						</table>
						<aside class="notes">
							<p>
								So, I went back and actually started to do the JetBrains tutorial step by step instead
								of jumping ahead and searched Wikipedia, trying to find CompSci articles that explained
								the correct way to do this.
							</p>
							<p>
								In order to support color syntax highlighting and mark syntax errors with the nice
								red squiggly under line, IntelliJ Elixir needed to be able to analyze Elixir syntax.
							</p>
							<p>
								Syntactic analysis is usually broken down into two parts: the first breaks the raw text
								into tokens and the second checks if those tokens are arranged in the correct order.
							</p>
							<p>
								In most programming languages, both lexers and parsers are built using generators that
								have an external DSL.  In Elixir, the lexer is built using Erlang directly because
								Erlang pattern matching is compact enough that a generator is unnecessary.
								Additionally, Elixir syntax contains some features that normal lexer generator aren't
								expecting.
							</p>
							<p>
								For IntelliJ Elixir, I used JFlex because it was the lexer generator recommended by
								JetBrain's plugin tutorial.
							</p>
							<p>
								For parsing Elixir does use a generator, called yecc, which generates Erlang code.
							</p>
							<p>
								For IntelliJ Elixir, I used JetBrains' GrammarKit.
							</p>
							<p>
								When I first started IntelliJ Elixir I didn't understand the important difference
								between these two stacks, but I hope to explain what I learned along the way to you.
							</p>
						</aside>
					</section>
					<section id="syntax-lexing">
						<h1>Lexing/Tokenizing</h1>
						<ol>
							<li>Match Input</li>
							<li>Emit Token</li>
						</ol>
						<aside class="notes">
							<p>
								The first step of syntactic analysis is lexing, also known as tokenizing.  Lexing
								breaks up the raw text into tokens, such as keywords, literals, operators, and
								identifiers.
							</p>
							<p>
								Input is matched using some pattern.  In native Elixir, this is pattern matching on
								Erlang string prefixes.  In IntelliJ Elixir's JFlex file, it's regular expressions.
							</p>
						</aside>
					</section>
					<section id="syntax-ignored">
						<h1>Ignoring Characters</h1>
						<table class="stretch">
							<thead>
							<tr>
								<th>Token</th>
								<th>Erlang</th>
								<th>JFlex</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<td>Comments</td>
								<td>
									<a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L133-L137">
										<pre><code class="erlang" data-trim style="font-size: 85%; line-height: 100%">
tokenize([$#|String], Line, Scope, Tokens) ->
  Rest = tokenize_comment(String),
  tokenize(Rest, Line, Scope, Tokens);

tokenize_comment("\r\n" ++ _ = Rest) -> Rest;
tokenize_comment("\n" ++ _ = Rest)   -> Rest;
tokenize_comment([_|Rest])           -> tokenize_comment(Rest);
tokenize_comment([])                 -> [].
										</code></pre>
									</a>
								</td>
								<td>
									<a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.0.2/src/org/elixir_lang/Elixir.flex#L21-L63">
										<pre><code data-trim>
COMMENT = "#" [^\r\n]* {EOL}?

&lt;YYINITIAL&gt; {
  {COMMENT} { yybegin(BODY); return ElixirTypes.COMMENT; }
}
&lt;BODY&gt; {
  {COMMENT} { return ElixirTypes.COMMENT; }
}
										</code></pre>
									</a>
								</td>
							</tr>
							<tr>
								<td>EOL</td>
								<td>
									<a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L320-L324">
										<pre><code class="erlang" data-trim>
tokenize("\n" ++ Rest, Line, Scope, Tokens) ->
  tokenize(Rest, Line + 1, Scope, eol(Line, newline, Tokens));

tokenize("\r\n" ++ Rest, Line, Scope, Tokens) ->
  tokenize(Rest, Line + 1, Scope, eol(Line, newline, Tokens));

eol(_Line, _Mod, [{',',_}|_] = Tokens)   -> Tokens;
eol(_Line, _Mod, [{eol,_,_}|_] = Tokens) -> Tokens;
eol(Line, Mod, Tokens) -> [{eol,Line,Mod}|Tokens].
										</code></pre>
									</a>
								</td>
								<td>
									<a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.0.2/src/org/elixir_lang/Elixir.flex#L18-L59">
										<pre><code data-trim style="font-size: 95%; line-height: 100%;">
EOL = \n|\r|\r\n

&lt;YYINITIAL&gt; {
  ({EOL}|{WHITE_SPACE})+      { yybegin(BODY);
                                return TokenType.WHITE_SPACE; }
}
&lt;BODY&gt; {
  {EOL}({EOL}|{WHITE_SPACE})* { return ElixirTypes.EOL; }
}
										</code></pre>
									</a>
								</td>
							</tr>
							<tr>
								<td>Whitespace</td>
								<td>
									<a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L478-L479">
										<pre><code class="erlang" data-trim style="font-size: 90%; line-height: 100%">
tokenize([T|Rest], Line, Scope, Tokens) when ?is_horizontal_space(T) ->
  tokenize(strip_horizontal_space(Rest), Line, Scope, Tokens);

strip_horizontal_space([H|T]) when ?is_horizontal_space(H) ->
  strip_horizontal_space(T);
strip_horizontal_space(T) ->
  T.
										</code></pre>
									</a>
								</td>
								<td>
									<a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.0.2/src/org/elixir_lang/Elixir.flex#L21-L63">
										<pre><code data-trim>
COMMENT = "#" [^\r\n]* {EOL}?

&lt;YYINITIAL&gt; {
  {COMMENT} { yybegin(BODY); return ElixirTypes.COMMENT; }
}
&lt;BODY&gt; {
  {COMMENT} { return ElixirTypes.COMMENT; }
}
										</code></pre>
									</a>
								</td>
							</tr>
							</tbody>
						</table>
						<aside class="notes">
							<p>
								In addition to turning runs of characters into single tokens, the lexer can be used
								to filter out runs that don't affect the meaning of code, such as spaces, extra new
								lines and comments.
							</p>
							<p>
								The JFlex code has two states because in v0.0.2, I used the Y-Y-INITIAL state to ignore
								newlines or whitespace at the beginning of the file.
							</p>
							<p>
								I also made the assumption that runs of EOLs could be ignored at the parser level.
							</p>
                            <p>
                                The Erlang lexer in elixir tokenizer dot erl processes the raw text as a char list.
                                Pattern matching on the head of the list and then recursively calling tokenize on the
                                rest of the raw text.  The Erlang lexer only keeps track of the effect of ignored
                                characters on the current line number, which was the only metadata in Elixir v0.14.3.
                            </p>
                            <p>
                                In contrast, the JFlex lexer processes the raw text as unicode characters.  Regular
                                expressions and references to other named regular expressions (as seen in COMMENT using
                                EOL) can be used to match text with the longest match in a given state while in the
                                Erlang Lexer, the order matches the order of the clauses.  The JFlex lexer emits a token
                                for even ignored characters because in an editor, unlike a compiler, one cares about
                                comments, whitespace and extra newlines.
                            </p>
						</aside>
					</section>
                    <section id="syntax-base-integers">
                        <h1>Base Integers</h1>
                        <table class="stretch">
                            <thead>
                            <tr>
                                <th>Erlang</th>
                                <th>JFlex</th>
                            </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>
                                    <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L121-L131">
                                        <pre><code data-trim style="font-size: 70%; line-height: 100%">
tokenize([$0,X,H|T], Line, Scope, Tokens) when (X == $x orelse X == $X), ?is_hex(H) ->
  {Rest, Number} = tokenize_hex([H|T], []),
  tokenize(Rest, Line, Scope, [{number, Line, Number}|Tokens]);

tokenize([$0,B,H|T], Line, Scope, Tokens) when (B == $b orelse B == $B), ?is_bin(H) ->
  {Rest, Number} = tokenize_bin([H|T], []),
  tokenize(Rest, Line, Scope, [{number, Line, Number}|Tokens]);

tokenize([$0,H|T], Line, Scope, Tokens) when ?is_octal(H) ->
  {Rest, Number} = tokenize_octal([H|T], []),
  tokenize(Rest, Line, Scope, [{number, Line, Number}|Tokens]);

tokenize_hex([H|T], Acc) when ?is_hex(H) -> tokenize_hex(T, [H|Acc]);
tokenize_hex(Rest, Acc) -> {Rest, list_to_integer(lists:reverse(Acc), 16)}.

tokenize_octal([H|T], Acc) when ?is_octal(H) -> tokenize_octal(T, [H|Acc]);
tokenize_octal(Rest, Acc) -> {Rest, list_to_integer(lists:reverse(Acc), 8)}.

tokenize_bin([H|T], Acc) when ?is_bin(H) -> tokenize_bin(T, [H|Acc]);
tokenize_bin(Rest, Acc) -> {Rest, list_to_integer(lists:reverse(Acc), 2)}.

-define(is_hex(S), ?is_digit(S) orelse (S >= $A andalso S =< $F) orelse (S >= $a andalso S =< $f)).
-define(is_bin(S), S >= $0 andalso S =< $1).
-define(is_octal(S), S >= $0 andalso S =< $7).

-define(is_digit(S), S >= $0 andalso S =< $9).
                                        </code></pre>
                                    </a>
                                </td>
                                <td>
                                    <a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.0.2/src/org/elixir_lang/Elixir.flex#L27-L65">
                                        <pre><code data-trim>
BINARY_INTEGER = "0" [Bb][01]+
HEXADECIMAL_INTEGER = "0" [Xx][A-Fa-f0-9]+
OCTAL_INTEGER = "0" o?[0-7]+
INTEGER = {BINARY_INTEGER} | {HEXADECIMAL_INTEGER} | {OCTAL_INTEGER}

&lt;YYINITIAL&gt; {
  {INTEGER} { yybegin(BODY); return ElixirTypes.NUMBER; }
}
&lt;BODY&gt; {
  {INTEGER} { return ElixirTypes.NUMBER; }
}
                                        </code></pre>
                                    </a>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                        <aside class="notes">
                            <p>
                                Base integers is the terminology elixir tokenizer dot erl uses for non-decimal integers,
                                such a binary, octal, and hexadecimal.
                            </p>
                            <p>
                                Elixir v0.14.3 is old enough that it still accepted zero-prefixed numbers as octal
                                instead of the current zero oh (<code>0o</code>).  Additionally, upper or lower case
                                B and X were allowed for binary and hexadecimal instead of just the lowercase allowed
                                now.
                            </p>
                            <p>
                                JFlex can use regular expression character classes and pipe (<code>|</code>) for 'or'
                                so it the JFlex definition can be much more compact than all the guard macros needed
                                to test the character values in Erlang.  Because all numbers will be highlighted the
                                same, I only need one <code>INTEGER</code> regular expression to match binary,
                                hexadecimal and octal numbers and use a common <code>NUMBER</code> token type.
                            </p>
                        </aside>
                    </section>
                    <section id="syntax-jflex-lexer-generation">
						<h1>JFlex Lexer Generation</h1>
						<ol class="stretch" style="font-size: 230%">
							<li>Regular Expressions</li>
							<li>
								<figure>
									<figcaption>Nondeterministic Finite Automaton</figcaption>
									<pre><code>Constructing NFA : 132 states in NFA</code></pre>
								</figure>
							</li>
							<li>
								<figure>
									<figcaption>Deterministic Finite Automaton</figcaption>
									<pre><code>Converting NFA to DFA</code></pre>
								</figure>
							</li>
							<li>
								<figure>
									<figcaption>Minimized Deterministic Finite Automaton</figcaption>
									<pre><code>45 states before minimization, 27 states in minimized DFA</code></pre>
								</figure>
							</li>
						</ol>
                        <aside class="notes">
                            <p>
                                The JFlex do flex file uses an external DSL, so it needs to be processed by JFlex, which
                                will go through a number of steps to combine the literal Java in braces for each
                                regular expression into a very efficient deterministinic finite automaton.
                            </p>
                            <p>
                                In the code I wrote, there are only 2 states, Y-Y-Initial (<code>YYINITIAL</code>) and
                                Body (<code>BODY</code>), which each have 4 and 5 regular expressions, respectively, so
                                JFlex is expanding those 9 state, regular expression tuples into 132 states.
                            </p>
                        </aside>
					</section>
                    <section id="syntax-finite-automaton">
                        <h1>Finite Automaton</h1>
                        <table>
                            <thead>
                            <tr>
                                <th></th>
                                <th>Non-Determininistic</th>
                                <th>Deterministic</th>
                            </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <th>Next State</th>
                                <td>Multiple</td>
                                <td>Single</td>
                            </tr>
                            <tr>
                                <th>Input</th>
                                <td>Single Character</td>
                                <td>Single Character</td>
                            </tr>
                            <tr>
                                <th>Accepts</th>
                                <td>Path exists to Accepting State</td>
                                <td>In Accepting State</td>
                            </tr>
                            </tbody>
                        </table>
                        <aside class="notes">
                            <p>
                                The different steps of JFlex's lexer generation mention finite automaton, which is just
                                another name for finite state machines.
                            </p>
                            <p>
                                The lexer starts with a NFA, or Non-deterministic Finite Automaton, and converts it
                                to a DFA, or Deterministic Finite Automaton.
                            </p>
                            <p>
                                The conversion is one of those nice things in computer science that can be proven
                                possible and has various algorithms to simplify the process.  It uses a process called
                                power set construction where each state in the DFA represents a combinations of states
                                from the NFA that can be transitioned to with the same input.  This means the DFA could
                                end up with 2 to the n (<code>2<sup>n</sup></code>) states where n is the number of
                                states in the NFA.
                            </p>
                            <p>
                                Although JFlex does all this generation for one, it's important to pay attention to
                                see if the states are exploding as it can lead to slower lexing as the transition
                                table will be larger.
                            </p>
                        </aside>
                    </section>
                    <section id="syntax-jflex-generated-lexer-packing">
                        <h1>JFlex Generated Lexer - Packing</h1>
                        <pre><code class="java stretch" data-trim>
class ElixirFlexLexer implements FlexLexer {
  /** lexical states */
  public static final int YYINITIAL = 0;
  public static final int BODY = 2;

  /**
   * Translates characters to character classes
   */
  private static final String ZZ_CMAP_PACKED =
    "\11\0\1\3\1\1\1\0\1\3\1\2\22\0\1\3\2\0\1\4"+
    "\14\0\1\5\1\7\6\13\2\11\7\0\1\11\1\6\4\11\21\0"+
    "\1\10\10\0\1\11\1\6\4\11\10\0\1\12\10\0\1\10\uff87\0";

  /**
   * Translates DFA states to action switch labels.
   */
  private static final String ZZ_ACTION_PACKED_0 =
    "\2\0\1\1\1\2\1\3\1\1\1\4\1\5\1\6"+
    "\1\7\1\4\2\3\1\10\3\0\2\7\1\11\3\0"+
    "\2\10\2\11";

  /**
   * Translates a state to a row index in the transition table
   */
  private static final String ZZ_ROWMAP_PACKED_0 =
    "\0\0\0\14\0\30\0\44\0\60\0\74\0\30\0\110"+
    "\0\124\0\140\0\154\0\30\0\170\0\204\0\220\0\234"+
    "\0\204\0\30\0\250\0\264\0\300\0\314\0\264\0\220"+
    "\0\234\0\300\0\314";

  /**
   * The transition table of the DFA
   */
  private static final String ZZ_TRANS_PACKED_0 =
    "\1\3\3\4\1\5\1\6\6\3\1\7\2\10\1\11"+
    "\1\12\1\13\6\7\15\0\3\4\10\0\1\5\1\14"+
    "\1\15\11\5\5\0\1\16\1\17\1\16\1\20\1\0"+
    "\1\21\1\16\1\0\3\10\13\0\1\11\10\0\1\12"+
    "\1\22\1\23\11\12\5\0\1\24\1\25\1\24\1\26"+
    "\1\0\1\27\1\24\1\0\1\14\17\0\1\16\1\0"+
    "\1\16\3\0\1\16\5\0\1\30\1\0\1\30\11\0"+
    "\3\31\1\0\1\31\1\0\1\31\1\0\1\22\17\0"+
    "\1\24\1\0\1\24\3\0\1\24\5\0\1\32\1\0"+
    "\1\32\11\0\3\33\1\0\1\33\1\0\1\33";
}
                        </code></pre>
                        <aside class="notes">
                            <p>
                                JFlex can produce very efficient lexing code, but it comes at the cost of the code being
                                almost incomprehensible and very hard to debug.
                            </p>
                            <p>
                                For one thing, the transition tables and translates between the minimized DFA states
                                and the original states from the dot flex files are all in packed Strings.  I've never
                                tried to unpack and decipher those for errors even though looking at state transition
                                tables is a good approach for finding bugs in finite state machines in college.
                            </p>
                        </aside>
                    </section>
                    <section id="syntax-jflex-generated-lexer-switch">
                        <h1>JFlex Generated Lexer - Switch</h1>
                        <pre><code class="java stretch" data-trim>
switch (zzAction < 0 ? zzAction : ZZ_ACTION[zzAction]) {
  case 5:
    { return ElixirTypes.EOL;
    }
  case 10: break;
  case 2:
    { yybegin(BODY); return TokenType.WHITE_SPACE;
    }
  case 11: break;
  case 3:
    { yybegin(BODY); return ElixirTypes.COMMENT;
    }
  case 12: break;
  case 9:
    { return ElixirTypes.NUMBER;
    }
  case 13: break;
  case 1:
    { yybegin(BODY); return TokenType.BAD_CHARACTER;
    }
  case 14: break;
  case 7:
    { return ElixirTypes.COMMENT;
    }
  case 15: break;
  case 8:
    { yybegin(BODY); return ElixirTypes.NUMBER;
    }
  case 16: break;
  case 4:
    { return TokenType.BAD_CHARACTER;
    }
  case 17: break;
  case 6:
    { return TokenType.WHITE_SPACE;
    }
  case 18: break;
  default:
    if (zzInput == YYEOF && zzStartRead == zzCurrentPos) {
      zzAtEOF = true;
      zzDoEOF();
      return null;
    }
    else {
      zzScanError(ZZ_NO_MATCH);
    }
}
                        </code></pre>
                        <aside class="notes">
                            <p>
                                From the constants at the top of the class, I know <code>BODY</code> is <code>2</code>,
                                but the switch statement is on Z-Z-Action (<code>zzAction</code>), so it's not
                                necessarily even the same numbering and the Java code for Y-Y-Initial
                                (<code>YYINITIAL</code>) and BODY (<code>BODY</code>) states seems to be intermixed,
                                so the only way I've found to debug the lexer crashing or hanging is break-points in
                                braces from the Java code and test sequences.
                            </p>
                        </aside>
                    </section>
                    <section id="syntax-v0.0.2">
                        <h1>v0.0.2</h1>
                        <table>
							<thead>
							<tr>
								<th rowspan="2">Date</th>
								<th colspan="2">Days</th>
								<th colspan="2">Commits</th>
								<th>Version</th>
							</tr>
							<tr>
								<th>Delta</th>
								<th>Total</th>
								<th>Delta</th>
								<th>Total</th>
								<th>Commits/Day</th>
							</tr>
							</thead>
							<tbody>
                            <tr>
								<td>2014&#8209;08&#8209;03</td>
								<td>1</td>
								<td>7</td>
								<td>14</td>
								<td>33</td>
								<td>14.00</td>
							</tr>
                            </tbody>
                        </table>
                        <ul>
                            <li>
                                <p>Enhancements</p>
                                <ul>
                                    <li>Comments</li>
                                    <li>Binary numbers</li>
                                    <li>Hexadecimal numbers</li>
                                    <li>Octal numbers</li>
                                </ul>
                            </li>
                            <li>
                                <p>Bug Fixes</p>
                                <ul>
                                    <li>Parser no longer freezes</li>
                                </ul>
                            </li>
                        </ul>
                        <aside class="notes">
                            <p>
                                With version oh dot oh dot two (<code>v0.0.2</code>), IntelliJ Elixir no longer froze
                                the IDE, but I could only parse Comments or base integers, but I had started to under
                                how to generate a lexer properly using JFlex.
                            </p>
                        </aside>
                    </section>
				</section>
                <section class="stack">
                    <section id="interpolation">
                        <h1>Interpolation</h1>
                        <ul>
							<li>
								<a href="#/interpolation-interpolation">Interpolation</a>
							</li>
							<li>
								<a href="#/interpolation-computational-hierarchy">Computational Hierarchy</a>
							</li>
                            <li>
                                <a href="#/interpolation-elixir-native">Elixir Native</a>
                            </li>
                            <li>
                                <a href="#/interpolation-nesting-limit">Nesting Limit</a>
                            </li>
                            <li>
                                <a href="#/interpolation-jflex">JFlex</a>
                            </li>
                            <li>
                                <a href="#/interpolation-v0.0.3">v0.0.3</a>
                            </li>
                        </ul>
                    </section>
					<section id="interpolation-interpolation">
						<h1>Interpolation</h1>
						<pre><code class="elixir" data-trim>
iex> greeting = "Hello #{"W#{"or"}ld"}"
"Hello World"
iex> tuple = "A tuple #{inspect {"Containing an #{:interpolated} string"}}"
"A tuple {\"Containing an interpolated string\"}"
						</code></pre>
						<ul>
							<li>
								Starts with <code>#{</code> and ends with <code>}</code>
							</li>
							<li>
								Valid in Char Lists, Strings, and (interpolating) Sigils
							</li>
							<li>
								Recursive
							</li>
						</ul>
						<aside class="notes">
							<p>
								Add support for interpolation was tricky.  At first glance the hash opening curly and
								closing curly that surround interpolation should work just curly braces in a language
								like C or Java, but the braces in C or Java can just be lexed and the parser can decide
								about whether they are matched.  In languages like Ruby or Elixir that support
								interpolation, whether the you're parsing fragments for the string, char list or sigil
								or if you're in normal code needs to be tracked as fragments will be syntax highlighted
								and parsed differently than normal code.  Finally, code inside interpolation can
								itself have strings, char lists, or sigil that also contain interpolation, recursively.
							</p>
							<p>
								This recursion means that a non-deterministic finite automaton as generated by JFlex
								can no longer parser Elixir!
							</p>
						</aside>
					</section>
					<section id="interpolation-computational-hierarchy">
						<h1>Computational Heirarchy</h1>
						<table>
							<thead>
							<tr>
								<th>Language Class</th>
								<th>Computational Model</th>
								<th>Example</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<td>Regular</td>
								<td>Finite Automaton/State Machine</td>
								<td>Multiples of 3 in binary</td>
							</tr>
							<tr>
								<td>Context-Free</td>
								<td>Pushdown Automaton</td>
								<td>Balanced Parentheses</td>
							</tr>
							<tr>
								<td>Decidable</td>
								<td>(Always-halting) Turing machine</td>
								<td><code>a<sup>n</sup>b<sup>n</sup>c<sup>n</sup></code></td>
							</tr>
							<tr>
								<td>Semidecidable</td>
								<td>Turing machine</td>
								<td>Halting Problem</td>
							</tr>
							</tbody>
						</table>
						<aside class="notes">
							<p>
								Finite Automatons can lex regular languages, which are languages that match formal
								regular expressions.  Formal regular expression only allow pipe (<code>|</code>) for or,
								parentheses (<code>()</code>) for grouping, and asterisk (<code>*</code>) for Kleene
								star, which means zero or more.  They also can have question mark (<code>?</code>) to
								mean zero or one, if they can't use a symbol for no input, which would be lowercase
								epsilon formally.
							</p>
							<p>
								Context-free languages are a step above regular expressions and can be lexed by pushdown
								automatons, which have a stack for keeping track of state.  A pushdown automaton can use
								the current state along with the current input to decide whether parentheses are matched
								by pushing opening parentheses onto a stack and popping on closing parentheses.  If
								you try to pop when the stack is empty, then you have an unmatched closing parenthesis
								and if the string ends with a non-empty stack then you have an unmatched opening
								parenthesis.
							</p>
							<p>
								You may be thinking, "Wait! I know I can match parentheses with a regex in Ruby or Perl!"
								Well, you can, but this is because the back references to previous groups supported
								in Ruby with slash g (<code>\g</code>) and question mark R in Perl and Perl-Compatible
								Regular Expressions (<code>?R</code>).  This feature is not actually part of formal
								regular expressions and actually promotes extend regular expressions to pushdown
								automaton.
							</p>
							<p>
								When writing compilers and IDEs, designers have to care about the computational hierarchy
								because performance guarantees get fuzzy and get more complex until you hit
								semidecidable and Turing machines, which may just spin forever on bad input.
							</p>
						</aside>
					</section>
					<section id="interpolation-elixir-native" style="font-size: 85%">
						<h1>Elixir Native Interpolation</h1>
						<figure>
							<figcaption>
								<a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L234-L529">
									<code>lib/elixir/src/elixir_tokenizer.erl</code>
								</a>
							</figcaption>
							<pre><code class="erlang" data-trim>
tokenize([$"|T], Line, Scope, Tokens) ->
  handle_strings(T, Line, $", Scope, Tokens);
tokenize([$'|T], Line, Scope, Tokens) ->
  handle_strings(T, Line, $', Scope, Tokens);

handle_strings(T, Line, H, Scope, Tokens) ->
  case elixir_interpolation:extract(Line, Scope, true, T, H) of
    {error, Reason} ->
      interpolation_error(Reason, [H|T], Tokens, " (for string starting at line ~B)", [Line]);
    {NewLine, Parts, [$:|Rest]} when ?is_space(hd(Rest)) ->
      Unescaped = unescape_tokens(Parts),
      Key = case Scope#elixir_tokenizer.existing_atoms_only of
        true  -> kw_identifier_safe;
        false -> kw_identifier_unsafe
      end,
      tokenize(Rest, NewLine, Scope, [{Key, Line, Unescaped}|Tokens]);
    {NewLine, Parts, Rest} ->
      Token = {string_type(H), Line, unescape_tokens(Parts)},
      tokenize(Rest, NewLine, Scope, [Token|Tokens])
  end.
							</code></pre>
						</figure>
						<figure>
							<figcaption>
								<a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_interpolation.erl#L39-L50">
									<code>lib/elixir/src/elixir_interpolation.erl</code>
								</a>
							</figcaption>
							<pre><code class="erlang" data-trim>
extract(Line, Scope, true, [$#, ${|Rest], Buffer, Output, Last) ->
  Output1 = build_string(Line, Buffer, Output),

  case elixir_tokenizer:tokenize(Rest, Line, Scope) of
    {error, {EndLine, _, "}"}, [$}|NewRest], Tokens} ->
      Output2 = build_interpol(Line, Tokens, Output1),
      extract(EndLine, Scope, true, NewRest, [], Output2, Last);
    {error, Reason, _, _} ->
      {error, Reason};
    {ok, _EndLine, _} ->
      {error, {string, Line, "missing interpolation terminator:}", []}}
  end;
							</code></pre>
						</figure>
						<aside class="notes">
							<p>
								In native Elixir, elixir tokenizer colon tokenize slash four
								(<code>elixir_tokenizer:tokenize/4</code>) calls handle strings slash 5
								(<code>handle_strings/5</code>, which calls elixir interpolation colon
								extract, which calls elixir tokenizer colon tokenizer slash 3
								(<code>elixir_tokenizer:tokenize/3</code>), which calls slash 4, meaning the native
								lexer uses normal Erlang recursion.
							</p>
							<p>
								Note: the recursive call to tokenize is an argument to case, so
								interpolation handling is not tail-recursive so if you got cheeky you could blow the
								stack with enough levels of nested interpolation.
							</p>
						</aside>
					</section>
					<section id="interpolation-nesting-limit">
						<h1>Interpolation Nesting Limit</h1>
						<pre><code class="elixir stretch" data-trim style="font-size: 160%; line-height: 100%;">
levels = 10_000_000
open = Stream.repeatedly(fn -> ~S|" #{| end) |>
       Enum.take(levels) |>
       Enum.join; nil
close = Stream.repeatedly(fn -> ~S|} "| end) |>
        Enum.take(levels) |>
        Enum.join; nil
:ok = "#{open}#{close}" |>
      String.to_char_list |>
      :elixir_tokenizer.tokenize(0, []) |>
      elem(0)
						</code></pre>
						<aside class="notes">
							<p>
								That being said, although 10 million levels of nesting took a long time to run and ate
                                all my memory, I wasn't able to actually hit a stack limit on my Mac Book Pro.
							</p>
						</aside>
					</section>
					<section id="interpolation-jflex">
						<h1>JFlex Interpolation</h1>
						<figure>
							<figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.0.3/src/org/elixir_lang/Elixir.flex">
                                    <code>src/org/elixir_lang/Elixr.flex</code>
                                </a>
							</figcaption>
                            <pre><code class="stretch" data-trim style="font-size: 165%; line-height: 100%;">
%{
  private java.util.Stack&lt;Integer&gt; lexicalStateStack = new java.util.Stack&lt;Integer&gt;();
%}

&lt;YYINITIAL&gt; {
  {DOUBLE_QUOTES}  { lexicalStateStack.push(BODY);
                     yybegin(DOUBLE_QUOTED_STRING);
                     return ElixirTypes.DOUBLE_QUOTES; }
}

&lt;DOUBLE_QUOTED_STRING&gt; {
  {INTERPOLATION_START} { lexicalStateStack.push(yystate());
                          yybegin(INTERPOLATION);
                          return ElixirTypes.INTERPOLATION_START; }
  {DOUBLE_QUOTES}       { int previousLexicalState = lexicalStateStack.pop();
                          yybegin(previousLexicalState);
                          return ElixirTypes.DOUBLE_QUOTES; }
}

&lt;BODY, INTERPOLATION&gt; {
  {DOUBLE_QUOTES} { lexicalStateStack.push(yystate());
                    yybegin(DOUBLE_QUOTED_STRING);
                    return ElixirTypes.DOUBLE_QUOTES; }
}

&lt;INTERPOLATION&gt; {
  {INTERPOLATION_END} { int previousLexicalState = lexicalStateStack.pop();
                        yybegin(previousLexicalState);
                        return ElixirTypes.INTERPOLATION_END; }
}
                            </code></pre>
						</figure>
						<aside class="notes">
							<p>
								JFlex's flex DSL only supports creating finite automaton, so how did I enhance the
								generated parser so it was a pushdown automaton?  I added a manually managed stack
								in the Java code that I can run on each rule match.
							</p>
                            <p>
                                The Java code at the top in percent curly braces is injected directly into the generated
                                parser.  It sets up an integer stack to track the current lexical state.
                            </p>
                            <p>
                                If the lexer hits a non-escaped double quote, it enters the
                                <code>DOUBLE_QUOTED_STRING</code> state, which treats the hash curly brace
                                (<code>#{</code>) of the interpolation start token special: it pushes the current state
                                on top the stack and begins the <code>INTERPOLATION</code> state.
                            </p>
                            <p>
                                The <code>INTERPOLATION</code> and <code>BODY</code> states are the same except
                                that <CODE>INTERPOLATION</CODE> needs to pop and restore the previous lexical state
                                if the closing curly brace (<code>}</code>) for <code>INTERPOLATION</code> is hit.
                            </p>
						</aside>
					</section>
                    <section id="interpolation-v0.0.3">
                        <h1>v0.0.3</h1>
                        <table style="font-size: 85%">
							<thead>
							<tr>
								<th rowspan="2">Date</th>
								<th colspan="2">Days</th>
								<th colspan="2">Commits</th>
								<th>Version</th>
							</tr>
							<tr>
								<th>Delta</th>
								<th>Total</th>
								<th>Delta</th>
								<th>Total</th>
								<th>Commits/Day</th>
							</tr>
							</thead>
							<tbody>
                            <tr>
								<td>2014&#8209;08&#8209;08</td>
								<td>5</td>
								<td>12</td>
								<td>10</td>
								<td>43</td>
								<td>2.00</td>
							</tr>
                            </tbody>
                        </table>
                        <ul>
                            <li>
                                <p>Enhancements</p>
                                <ul>
                                    <li>Char Lists</li>
                                    <li>
                                        <p>Strings</p>
                                        <ul>
                                            <li>Interpolation</li>
                                            <li>Escaped <code>#</code></li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>
                        </ul>
                        <aside class="notes">
                            <p>
                                In 5 days I was able to figure out how to convert the JFlex finite automaton
                                to a pushdown automaton by following the formal definition that pushdown automaton
                                just is a finite automaton with a stack that it can consult for transition logic.
                            </p>
                        </aside>
                    </section>
                </section>
                <section class="stack">
                    <section id="sigil">
                        <h1>Sigil</h1>
                        <ul>
                            <li>
                                <a href="#/sigil-elixir-native">Elixir Native</a>
                            </li>
                            <li>
                                <a href="#/sigil-highlighting-dimensions">Highlighting Dimensions</a>
                            </li>
                            <li>
                                <a href="#/sigil-tilde">Tilde</a>
                            </li>
                            <li>
                                <a href="#/sigil-name">Name</a>
                            </li>
                            <li>
                                <a href="#/sigil-promoter">Promoter</a>
                            </li>
                            <li>
                                <a href="#/sigil-terminator">Terminator</a>
                            </li>
                            <li>
                                <a href="#/sigil-modifiers">Modifiers</a>
                            </li>
                            <li>
                                <a href="#/sigil-parser">Parser</a>
                            </li>
                            <li>
                                <a href="#/sigil-v0.1.0">v0.1.0</a>
                            </li>
                        </ul>
                    </section>
                    <section id="sigil-elixir-native">
                        <h1>Native Elixir</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L141-L158">
                                    <code>lib/elixir/src/elixir_tokenizer.erl</code>
                                </a>
                                <pre><code class="erlang stretch" data-trim style="font-size: 125%; line-height: 100%">
tokenize([$~,S,H,H,H|T] = Original, Line, Scope, Tokens) when ?is_quote(H), ?is_upcase(S) orelse ?is_downcase(S) ->
  case extract_heredoc_with_interpolation(Line, Scope, ?is_downcase(S), T, H) of
    {ok, NewLine, Parts, Rest} ->
      {Final, Modifiers} = collect_modifiers(Rest, []),
      tokenize(Final, NewLine, Scope, [{sigil, Line, S, Parts, Modifiers}|Tokens]);
    {error, Reason} ->
      {error, Reason, Original, Tokens}
  end;

tokenize([$~,S,H|T] = Original, Line, Scope, Tokens) when ?is_sigil(H), ?is_upcase(S) orelse ?is_downcase(S) ->
  case elixir_interpolation:extract(Line, Scope, ?is_downcase(S), T, sigil_terminator(H)) of
    {NewLine, Parts, Rest} ->
      {Final, Modifiers} = collect_modifiers(Rest, []),
      tokenize(Final, NewLine, Scope, [{sigil, Line, S, Parts, Modifiers}|Tokens]);
    {error, Reason} ->
      Sigil = [$~,S,H],
      interpolation_error(Reason, Original, Tokens, " (for sigil ~ts starting at line ~B)", [Sigil, Line])
  end;
                                </code></pre>
                            </figcaption>
                        </figure>
                        <aside class="notes">
                            <p>
                                Native Elixir only cares whether the sigil is a heredoc (in the top clause) or a line
                                (in the bottom clause).
                            </p>
                        </aside>
                    </section>
                    <section id="sigil-highlighting-dimensions">
                        <h1>Highlighting Dimensions</h1>
                        <table>
                            <thead>
                            <tr>
                                <th>Dimension</th>
                                <th>Values</th>
                            </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>Name</td>
                                <td>
                                    <ul>
                                        <li>CharListSigil</li>
                                        <li>Regex</li>
                                        <li>Sigil</li>
                                        <li>StringSigil</li>
                                        <li>Words</li>
                                    </ul>
                                </td>
                            </tr>
                            <tr>
                                <td>Interpolation</td>
                                <td>
                                    <ul>
                                        <li>Interpolated</li>
                                        <li>Literal</li>
                                    </ul>
                                </td>
                            </tr>
                            <tr>
                                <td>Lines</td>
                                <td>
                                    <ul>
                                        <li>Heredoc</li>
                                        <li>Lined</li>
                                    </ul>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                        <aside class="notes">
                            <p>
                                For an IDE, it's not enough to detect that the syntax is correct for the sigils, ideally
                                we'd want each sigil to highlight in a different color and the highlighting needs to
                                be different for each literal vs interpolated so that users can spot if an escape
                                escape or interpolation is used in a non-interpolating literal.
                            </p>
                            <p>
                                These considerations mean I needed the tokenizer to produce different tokens for each
                                combination of sigil name and interpolated vs literal.  There is a 3rd dimension of
                                whether the sigil is a line or herdoc, which is important since leading spaces
                                are significant and can't be treated as simple, ignored, whitespace in heredocs.
                            </p>
                            <p>
                                The Sigil name is used for any generic sigil that may be in a user library that uses a
                                character for a name not used by the Kernel.
                            </p>
                        </aside>
                    </section>
                    <section id="sigil-tilde">
                        <h1>Tilde</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/71c39c30850b54574f0762cc80af3355bc9ef8c9/src/org/elixir_lang/Elixir.flex#L296-L297">
                                    <code>src/org/elixir_lang/Elixir.flex</code>
                                </a>
                            </figcaption>
                            <pre><code class="stretch" data-trim style="font-size: 395%; line-height: 100%">
&lt;BODY, INTERPOLATION&gt; {
  {TILDE} { pushAndBegin(SIGIL);
            return ElixirTypes.TILDE; }
}
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                The flex rule starts the same as tokenize's pattern match with tilde (<code>~</code>),
                                but since JFlex only allow tokens that use the entire text of the match, I need to match
                                the leading tilde and then jump to another state so I can match the sigil name as a
                                separate token.
                            </p>
                        </aside>
                    </section>
                    <section id="sigil-name">
                        <h1>Name</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/71c39c30850b54574f0762cc80af3355bc9ef8c9/src/org/elixir_lang/Elixir.flex#L397-L401">
                                    <code>src/org/elixir_lang/Elixir.flex</code>
                                </a>
                            </figcaption>
                            <pre><code class="stretch" data-trim style="font-size: 350%; line-height: 100%">
SIGIL_NAME = [A-Za-z]

&lt;SIGIL&gt; {
  {SIGIL_NAME} { nameSigil(yytext());
                 yybegin(NAMED_SIGIL);
                 return sigilNameType(); }
}
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                The sigil state only accepts single alphabetical characters and then jumps to the next
                                state so that the single name can be a separate token.
                            </p>
                            <p>
                                nameSigil adds the character to the stack state and then sigilNameType pulls the token
                                type for that character back out.  This helps unify the API for the pre-defined sigil
                                names and the catchall for user defined sigils.
                            </p>
                        </aside>
                    </section>
                    <section id="sigil-promoter">
                        <h1>Promoter</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/71c39c30850b54574f0762cc80af3355bc9ef8c9/src/org/elixir_lang/Elixir.flex#L183-L395">
                                    <code>src/org/elixir_lang/Elixir.flex</code>
                                </a>
                                <pre><code class="stretch" data-trim style="font-size: 190%; line-height: 100%">
SIGIL_BRACES_PROMOTER = "{"
SIGIL_BRACKETS_PROMOTER = "["
SIGIL_CHEVRONS_PROMOTER = "<"
SIGIL_DOUBLE_QUOTES_PROMOTER = "\""
SIGIL_FORWARD_SLASH_PROMOTER = "/"
SIGIL_PARENTHESES_PROMOTER = "("
SIGIL_PIPE_PROMOTER = "|"
SIGIL_SINGLE_QUOTES_PROMOTER = "'"

SIGIL_PROMOTER = {SIGIL_BRACES_PROMOTER} |
                 {SIGIL_BRACKETS_PROMOTER} |
                 {SIGIL_CHEVRONS_PROMOTER} |
                 {SIGIL_DOUBLE_QUOTES_PROMOTER} |
                 {SIGIL_FORWARD_SLASH_PROMOTER} |
                 {SIGIL_PARENTHESES_PROMOTER} |
                 {SIGIL_PIPE_PROMOTER} |
                 {SIGIL_SINGLE_QUOTES_PROMOTER}

&lt;NAMED_SIGIL&gt; {
  {SIGIL_HEREDOC_PROMOTER} { setPromoter(yytext());
                             yybegin(GROUP_HEREDOC_START);
                             return promoterType(); }
  {SIGIL_PROMOTER}         { setPromoter(yytext());
                             yybegin(GROUP);
                             return promoterType(); }
}
                                </code></pre>
                            </figcaption>
                        </figure>
                        <aside class="notes">
                            <p>
                                Unlike Strings, which only use double quotes or Char List that only use single quotes,
                                any sigil name can use any promoter, which is why the NAME_SIGIL state differs from
                                the normal quote and start quote rule.
                            </p>
                            <p>
                                If anyone has better terminology for this let me know.  I picked promoter because
                                terminator was used in the native implementation and the oppose of a terminator in a DNA
                                sequence is a promoter.
                            </p>
                        </aside>
                    </section>
                    <section id="sigil-terminator">
                        <h1>Terminator</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/71c39c30850b54574f0762cc80af3355bc9ef8c9/src/org/elixir_lang/Elixir.flex#L326-L355">
                                    <code>src/org/elixir_lang/Elixir.flex</code>
                                </a>
                                <pre><code class="stretch" data-trim style="font-size: 165%; line-height: 100%">
&lt;GROUP&gt; {
  {GROUP_TERMINATOR} {
                       if (isTerminator(yytext())) {
                         org.elixir_lang.lexer.StackFrame stackFrame = pop();
                         yybegin(stackFrame.getLastLexicalState());
                         return stackFrame.terminatorType();
                       } else {
                         return fragmentType();
                       }
                     }
  {EOL}|.            { return fragmentType(); }

}

&lt;GROUP_HEREDOC_END&gt; {
  {GROUP_HEREDOC_TERMINATOR} {
                               if (isTerminator(yytext())) {
                                 if (isSigil()) {
                                   yybegin(SIGIL_MODIFIERS);
                                   return terminatorType();
                                 } else {
                                   org.elixir_lang.lexer.StackFrame stackFrame = pop();
                                   yybegin(stackFrame.getLastLexicalState());
                                   return stackFrame.terminatorType();
                                 }
                               } else {
                                 handleInState(GROUP_HEREDOC_LINE_BODY);
                               }
                             }
}
                                </code></pre>
                            </figcaption>
                        </figure>
                        <aside class="notes">
                            <p>
                                The regular expression to end a group or heredoc unfortunately has to contain all
                                <em>potential</em> terminators, not just the correct one that matches the active
                                promoter because the regular expression can't be dynamic based on the stack since
                                I added the stack to JFlex.
                            </p>
                            <p>
                                So, when a potential terminator is matched, is terminator (<code>isTerminator</code>)
                                checks that the text matches the promoter on the stack.  If it does match, then
                                the group or heredoc ends, but if it doesn't match then the potential terminator is
                                just treated as non-special text for the sigil, string, or char list.
                            </p>
                            <p>
                                When the terminator matches the promoter, there also needs to be check if this is a
                                sigil because unlike Char Lists or Strings, sigils can have characters after the
                                terminator to modify the sigil behavior
                            </p>
                        </aside>
                    </section>

                    <section id="sigil-modifiers">
                        <h1>Modifiers</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/71c39c30850b54574f0762cc80af3355bc9ef8c9/src/org/elixir_lang/Elixir.flex#L39-L407">
                                    <code>src/org/elixir_lang/Elixir.flex</code>
                                </a>
                            </figcaption>
                            <pre><code class="stretch" data-trim style="font-size: 200%; line-height: 100%">
%{
  private void handleInState(int nextLexicalState) {
    yypushback(yylength());
    yybegin(nextLexicalState);
  }
}

SIGIL_MODIFIER = [a-z]

&lt;SIGIL_MODIFIERS&gt; {
  {SIGIL_MODIFIER} { return ElixirTypes.SIGIL_MODIFIER; }
  {EOL}|.          { org.elixir_lang.lexer.StackFrame stackFrame = pop();
                     handleInState(stackFrame.getLastLexicalState()); }
}
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                The sigil modifiers (<code>SIGIL_MODIFIERS</code>) state uses an idiom that would
                                become common in elixir dot flex (<code>Elixir.flex</code>): the last rule in a
                                state matches either E-O-L or any character so that it can be handled in another
                                state.  Using this idiom, I was able to avoid duplicating rules in descendant state
                                and instead just poping the stack and going back to <code>BODY</code> or
                                <code>INTERPOLATION</code>.
                            </p>
                        </aside>
                    </section>
                    <section id="sigil-parser">
                        <h1>Parser</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/71c39c30850b54574f0762cc80af3355bc9ef8c9/src/org/elixir_lang/Elixir.bnf#L24-L102">
                                    <code>src/org/elixir_lang/Elixir.bnf</code>
                                </a>
                            </figcaption>
                            <pre><code class="stretch" data-trim style="font-size: 90%; line-height: 100%">
private interpolatedCharListSigil ::= TILDE INTERPOLATING_CHAR_LIST_SIGIL_NAME CHAR_LIST_SIGIL_PROMOTER interpolatedCharListBody CHAR_LIST_SIGIL_TERMINATOR
private interpolatedCharListBody ::= (interpolation | CHAR_LIST_FRAGMENT | VALID_ESCAPE_SEQUENCE)*
private interpolatedHeredocCharListSigil ::= TILDE INTERPOLATING_CHAR_LIST_SIGIL_NAME CHAR_LIST_SIGIL_HEREDOC_PROMOTER EOL
                                             interpolatedCharListBody
                                             CHAR_LIST_SIGIL_HEREDOC_TERMINATOR
private interpolatedHeredocRegex ::= TILDE INTERPOLATING_REGEX_SIGIL_NAME REGEX_HEREDOC_PROMOTER EOL
                                     interpolatedRegexBody
                                     REGEX_HEREDOC_TERMINATOR SIGIL_MODIFIER*
private interpolatedHeredocSigil ::= TILDE INTERPOLATING_SIGIL_NAME SIGIL_HEREDOC_PROMOTER EOL
                                     interpolatedSigilBody
                                     SIGIL_HEREDOC_PROMOTER SIGIL_MODIFIER*
private interpolatedHeredocStringSigil ::= TILDE INTERPOLATING_STRING_SIGIL_NAME STRING_SIGIL_HEREDOC_PROMOTER EOL
                                           interpolatedStringBody
                                           STRING_SIGIL_HEREDOC_TERMINATOR
private interpolatedHeredocWords ::= TILDE INTERPOLATING_WORDS_SIGIL_NAME WORDS_HEREDOC_PROMOTER EOL
                                     interpolatedWordsBody
                                     WORDS_HEREDOC_TERMINATOR SIGIL_MODIFIER*
private interpolatedRegex ::= TILDE INTERPOLATING_REGEX_SIGIL_NAME REGEX_PROMOTER interpolatedRegexBody REGEX_TERMINATOR SIGIL_MODIFIER*
private interpolatedRegexBody ::= (interpolation | REGEX_FRAGMENT | VALID_ESCAPE_SEQUENCE)*
private interpolatedSigil ::= TILDE INTERPOLATING_SIGIL_NAME SIGIL_PROMOTER interpolatedSigilBody SIGIL_TERMINATOR SIGIL_MODIFIER*
private interpolatedSigilBody ::= (interpolation | SIGIL_FRAGMENT | VALID_ESCAPE_SEQUENCE)*
private interpolatedStringSigil ::= TILDE INTERPOLATING_STRING_SIGIL_NAME STRING_SIGIL_PROMOTER interpolatedStringBody STRING_SIGIL_TERMINATOR
private interpolatedStringBody ::=  (interpolation | STRING_FRAGMENT | VALID_ESCAPE_SEQUENCE)*
private interpolatedWordsBody ::= (interpolation | WORDS_FRAGMENT | VALID_ESCAPE_SEQUENCE)*
private literalCharListBody ::= CHAR_LIST_FRAGMENT*
private literalCharListSigil ::= TILDE LITERAL_CHAR_LIST_SIGIL_NAME CHAR_LIST_SIGIL_PROMOTER literalCharListBody CHAR_LIST_SIGIL_TERMINATOR
private literalHeredocRegex ::= TILDE LITERAL_REGEX_SIGIL_NAME REGEX_HEREDOC_PROMOTER EOL
                                literalRegexBody
                                REGEX_HEREDOC_TERMINATOR SIGIL_MODIFIER*
private literalHeredocSigil ::= TILDE LITERAL_SIGIL_NAME SIGIL_HEREDOC_PROMOTER EOL
                                literalSigilBody
                                SIGIL_HEREDOC_TERMINATOR SIGIL_MODIFIER*
private literalHeredocStringSigil ::= TILDE LITERAL_STRING_SIGIL_NAME STRING_SIGIL_HEREDOC_PROMOTER EOL
                                      literalStringBody
                                      STRING_SIGIL_HEREDOC_TERMINATOR
private literalHeredocWords ::= TILDE LITERAL_WORDS_SIGIL_NAME WORDS_HEREDOC_PROMOTER EOL
                                literalWordsBody
                                WORDS_HEREDOC_TERMINATOR SIGIL_MODIFIER*
private literalRegex ::= TILDE LITERAL_SIGIL_NAME REGEX_PROMOTER literalRegexBody REGEX_TERMINATOR SIGIL_MODIFIER*
private literalRegexBody ::= REGEX_FRAGMENT*
private literalSigil ::= TILDE LITERAL_SIGIL_NAME SIGIL_PROMOTER literalSigilBody SIGIL_TERMINATOR SIGIL_MODIFIER*
private literalSigilBody ::= SIGIL_FRAGMENT*
private literalStringBody ::= STRING_FRAGMENT*
private literalStringSigil ::= TILDE LITERAL_STRING_SIGIL_NAME STRING_SIGIL_PROMOTER literalStringBody STRING_SIGIL_TERMINATOR
private literalWords ::=  TILDE LITERAL_SIGIL_NAME WORDS_PROMOTER literal WORDS_TERMINATOR SIGIL_MODIFIER*
private literalWordsBody ::= WORDS_FRAGMENT*
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                I was able to eliminate redundant code in the lexer by moving it to Java, but I couldn't
                                figure out how to do the same for the BNF for the parser, so there had to be separate
                                rule for each of the 20 combinations.
                            </p>
                            <p>
                                Keep all the rule pattern for heredocs and lines in sync would prove difficult and lead
                                to a few missed-update bugs.
                            </p>
                        </aside>
                    </section>
                    <section id="sigil-v0.1.0">
                        <h1>v0.1.0</h1>
                        <table>
                            <thead>
                            <tr>
								<th rowspan="2">Date</th>
								<th colspan="2">Days</th>
								<th colspan="2">Commits</th>
								<th>Version</th>
							</tr>
							<tr>
								<th>Delta</th>
								<th>Total</th>
								<th>Delta</th>
								<th>Total</th>
								<th>Commits/Day</th>
							</tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>2014&#8209;09&#8209;13</td>
								<td>36</td>
								<td>48</td>
								<td>64</td>
								<td>107</td>
								<td>1.78</td>
                            </tr>
                            </tbody>
                        </table>
                        <ul>
                            <li>
                                <p>Enhancements</p>
                                <ul>
                                    <li>
                                        Literal and interpolated sigils with highlighting
                                        <ul>
                                            <li>Char List Sigils (<code>~c</code> and <code>~C</code>) highlighted as 'Char List' in Settings.</li>
                                            <li>
                                                Regex Sigils (<code>~r</code> and <code>~R</code>) highlighted as 'Sigil' in Settings.
                                                <strong>NOTE: RegExp syntax is not internally highlighted yet</strong>
                                            </li>
                                            <li>String Sigils (<code>~s</code> and <code>~S</code> highlighted as 'String' in Settings.</li>
                                            <li>Word Sigils (<code>~w</code> and <code>~W</code> highlighted as 'Sigil' in Settings.</li>
                                            <li>Custom Sigils highlighted as 'Sigil' in Settings.</li>
                                            <li>Modifiers are highlighted on Regex, Word, and Custom while modifiers aren't allowed on CharList and String Sigils.</li>
                                        </ul>
                                </ul>
                                <p>Bug Fixes</p>
                                <ul>
                                    <li>Single-quoted strings are correctly referred to as 'Character List' now instead of 'String' in Settings.</li>
                                    <li>Double-quoted strings are correctly referred to as 'String' now instead of 'Interpolated String' in Settings.</li>
                                    <li>Non-Heredoc CharLists and Strings can be multiline.</li>
                                    <li>CharLists and Strings support interpolation and escape sequences.</li>
                                </ul>
                            </li>
                        </ul>
                        <aside class="notes">
                            <p>
                                v0.1.0 also included some bug fixes where my Ruby brain had leaked into what was allowed
                                in single and double quotes in Elixir.
                            </p>
                        </aside>
                    </section>
                </section>
                <section class="stack">
                    <section id="atoms">
                        <h1>Atoms</h1>
                        <ul>
							<li>
								<p>Elixir Native</p>
								<ul>
									<li>
										<a href="#/atoms-elixir-native-literal">Literal</a>
									</li>
									<li>
										<a href="#/atoms-elixir-native-fragments">Fragments</a>
									</li>
								</ul>
							</li>
							<li>
								<a href="#/atoms-colon">Colon</a>
							</li>
							<li>
								<a href="#/atoms-start">Start</a>
							</li>
							<li>
								<p>Elixir Native</p>
								<ul>
									<li>
										<a href="#/atoms-elixir-native-quoted">Quoted</a>
									</li>
									<li>
										<a href="#/atoms-elixir-native-operators">Operators</a>
									</li>
								</ul>
							</li>
							<li>
								<a href="#/atoms-parser">Parser</a>
							</li>
							<li>
                                <a href="#/atoms-v0.1.2">
                                    v0.1.2
                                </a>
                            </li>
                        </ul>
                    </section>
                    <section id="atoms-elixir-native-literal">
                        <h1>Elixir Native</h1>
						<h2>Literal</h2>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L254-L771">
                                    <code>lib/elixir/src/elixir_tokenizer.erl</code>
                                </a>
                            </figcaption>
                            <pre><code class="erlang stretch" data-trim style="font-size: 180%; line-height: 100%">
tokenize([$:,T|String] = Original, Line, Scope, Tokens) when ?is_atom_start(T) ->
  {Rest, Part} = tokenize_atom([T|String], []),
  case unsafe_to_atom(Part, Line, Scope) of
    {ok, Atom} ->
      tokenize(Rest, Line, Scope, [{atom, Line, Atom}|Tokens]);
    {error, Reason} ->
      {error, Reason, Original, Tokens}
  end;

tokenize_atom([H|T], Acc) when ?is_atom(H) ->
  tokenize_atom(T, [H|Acc]);

tokenize_atom([H|T], Acc) when H == $?; H == $! ->
  {T, lists:reverse([H|Acc])};

tokenize_atom(Rest, Acc) ->
  {Rest, lists:reverse(Acc)}.
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                A literal atom is built up as a list of characters that start with colon <code>:</code>.
                            </p>
                            <p>
                                The guards hint that that atom format is not uniform.
                            </p>
                        </aside>
                    </section>
                    <section id="atoms-elixir-native-fragments">
                        <h1>Elixir Native</h1>
						<h2>Fragments</h2>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/include/elixir.hrl#L50-L58">
                                    <code>lib/elixir/include/elixir.hrl</code>
                                </a>
                            </figcaption>
                            <pre><code class="erlang stretch" data-trim style="font-size: 145%; line-height: 100%">
-define(is_digit(S), S >= $0 andalso S =< $9).
-define(is_upcase(S), S >= $A andalso S =< $Z).
-define(is_downcase(S), S >= $a andalso S =< $z).

%% Atoms
-define(is_atom_start(S), ?is_quote(S) orelse ?is_upcase(S) orelse ?is_downcase(S) orelse (S == $_)).
-define(is_atom(S), ?is_identifier(S) orelse (S == $@)).

-define(is_identifier(S), ?is_digit(S) orelse ?is_upcase(S) orelse ?is_downcase(S) orelse (S == $_)).
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                As you can see, atoms need to start with quotes, an underscore or a letter, but
                                the body of can also includes digits and at (<code>@</code>), which is important
                                for node names.  Finally, an atom can optionally end with an exclamation point
                                (<code>!</code>) or question mark (<code>?</code>) to support functions with that name
                                format.
                            </p>
                        </aside>
                    </section>
                    <section id="atoms-colon">
                        <h1>Colon</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/2ce264275c4b307ef21f6e7efa764d69751e1a9a/src/org/elixir_lang/Elixir.flex#L177-L394">
                                    <code>src/org/elixir_lang/Elixir.flex</code>
                                </a>
                            </figcaption>
                            <pre><code data-trim>
COLON = :

&lt;BODY, INTERPOLATION&gt; {
  {COLON} { pushAndBegin(ATOM_START);
            return ElixirTypes.COLON; }
}
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                For <code>tokenize</code>, the colon (<code>:</code>) prefixing the atom value is thrown
                                away, but in an IDE, characters must be tokenized since they are editable and take up
                                space, so after tokenizing the colon, elixir dot flex (<code>Elixir.flex</code>) needs
                                to jump to a new state, atom start (<code>ATOM_START</code>)
                            </p>
                        </aside>
                    </section>
                    <section id="atoms-start">
                        <h1>Atom Start</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/2ce264275c4b307ef21f6e7efa764d69751e1a9a/src/org/elixir_lang/Elixir.flex#L113-L375">
                                    <code>src/org/elixir_lang/Elixir.flex</code>
                                </a>
                            </figcaption>
                            <pre><code class="stretch" data-trim style="font-size: 120%; line-height: 100%">
ATOM_START = [a-zA-Z_]

&lt;ATOM_START&gt; {
  {ATOM_START}     { yybegin(ATOM_BODY);
                     return ElixirTypes.ATOM_FRAGMENT; }
  {QUOTE_PROMOTER} { /* At the end of the quote, return the state (BODY or INTERPOLATION) before ATOM_START as anything
                        after the closing quote should be handle by the state prior to ATOM_START.  Without this,
                        EOL and WHITESPACE won't be handled correctly */
                     org.elixir_lang.lexer.StackFrame stackFrame = pop();
                     yybegin(stackFrame.getLastLexicalState());
                     startQuote(yytext());
                     return promoterType(); }
  {OPERATOR}       { org.elixir_lang.lexer.StackFrame stackFrame = pop();
                     yybegin(stackFrame.getLastLexicalState());
                     return ElixirTypes.ATOM_FRAGMENT; }
  {EOL}            { return TokenType.BAD_CHARACTER; }
}
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                The atom start state (<code>ATOM_START</code>) has rules for literal atoms starting
                                with atom start rule (<code>ATOM_START</code>), quote promoter
                                (<code>QUOTE_PROMOTER</code>) for quoted atoms and <code>OPERATOR</code> for operators
                                as atoms, since they don't follow the normal naming rules for atoms.
                            </p>
                        </aside>
                    </section>
                    <section id="atoms-elixir-native-quoted">
                        <h1>Elixir Native</h1>
						<h2>Quoted</h2>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L241-L252">
                                    <code>lib/elixir/src/elixir_tokenizer.erl</code>
                                </a>
                            </figcaption>
                            <pre><code class="erlang stretch" data-trim style="font-size: 150%; line-height: 100%">
tokenize([$:,H|T] = Original, Line, Scope, Tokens) when ?is_quote(H) ->
  case elixir_interpolation:extract(Line, Scope, true, T, H) of
    {NewLine, Parts, Rest} ->
      Unescaped = unescape_tokens(Parts),
      Key = case Scope#elixir_tokenizer.existing_atoms_only of
        true  -> atom_safe;
        false -> atom_unsafe
      end,
      tokenize(Rest, NewLine, Scope, [{Key, Line, Unescaped}|Tokens]);
    {error, Reason} ->
      interpolation_error(Reason, Original, Tokens, " (for atom starting at line ~B)", [Line])
  end;
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                Similar to how the quote promoter rule jumps to the normal quoting state, tokenize
                                calls elixir interpolation colon extract (<code>elixir_interpolation:extract</code>) to
                                handle the normal quote parsing and then treats it as an atom.
                            </p>
                        </aside>
                    </section>
                    <section id="atoms-elixir-native-operators">
                        <h1>Elixir Native</h1>
						<h2>Operators</h2>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_tokenizer.erl#L265-L304">
                                    <code>lib/elixir/src/elixir_tokenizer.erl</code>
                                </a>
                            </figcaption>
                            <pre><code class="erlang stretch" data-trim style="font-size: 155%; line-height: 100%">
tokenize(":..." ++ Rest, Line, Scope, Tokens) ->
  tokenize(Rest, Line, Scope, [{atom, Line, '...'}|Tokens]);
tokenize(":<<>>" ++ Rest, Line, Scope, Tokens) ->
  tokenize(Rest, Line, Scope, [{atom, Line, '<<>>'}|Tokens]);
tokenize(":%{}" ++ Rest, Line, Scope, Tokens) ->
  tokenize(Rest, Line, Scope, [{atom, Line, '%{}'}|Tokens]);
tokenize(":%" ++ Rest, Line, Scope, Tokens) ->
  tokenize(Rest, Line, Scope, [{atom, Line, '%'}|Tokens]);
tokenize(":{}" ++ Rest, Line, Scope, Tokens) ->
  tokenize(Rest, Line, Scope, [{atom, Line, '{}'}|Tokens]);

% ## Three Token Operators
tokenize([$:,T1,T2,T3|Rest], Line, Scope, Tokens) when
    ?unary_op3(T1, T2, T3); ?comp_op3(T1, T2, T3); ?and_op3(T1, T2, T3); ?or_op3(T1, T2, T3);
    ?arrow_op3(T1, T2, T3); ?hat_op3(T1, T2, T3) ->
  tokenize(Rest, Line, Scope, [{atom, Line, list_to_atom([T1,T2,T3])}|Tokens]);

% ## Two Token Operators
tokenize([$:,T1,T2|Rest], Line, Scope, Tokens) when
    ?comp_op2(T1, T2); ?rel_op2(T1, T2); ?and_op(T1, T2); ?or_op(T1, T2);
    ?arrow_op(T1, T2); ?in_match_op(T1, T2); ?two_op(T1, T2); ?stab_op(T1, T2);
    ?type_op(T1, T2) ->
  tokenize(Rest, Line, Scope, [{atom, Line, list_to_atom([T1,T2])}|Tokens]);

% ## Single Token Operators
tokenize([$:,T|Rest], Line, Scope, Tokens) when
    ?at_op(T); ?unary_op(T); ?capture_op(T); ?dual_op(T); ?mult_op(T);
    ?rel_op(T); ?match_op(T); ?pipe_op(T); T == $. ->
  tokenize(Rest, Line, Scope, [{atom, Line, list_to_atom([T])}|Tokens]);
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                elixir tokenizer (<code>elixir_tokenizer</code>) is more verbose because it can at best
                                combine patterns of the same
                            </p>
                        </aside>
                    </section>
                    <section id="atoms-parser">
                        <h1>Parser</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_parser.yrl#L26-L30">
                                    <code>lib/elixir/src/elixir_parser.yrl</code>
                                </a>
                            </figcaption>
                            <pre><code data-trim style="font-size: 185%; line-height: 100%">
Terminals
  number signed_number atom atom_safe atom_unsafe bin_string list_string sigil
                            </code></pre>
                        </figure>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/KronicDeth/intellij-elixir/blob/2ce264275c4b307ef21f6e7efa764d69751e1a9a/src/org/elixir_lang/Elixir.bnf#L24">
                                    <code>src/org/elixir_lang/Elixir.bnf</code>
                                </a>
                            </figcaption>
                            <pre><code data-trim style="font-size: 185%; line-height: 100%">
atom ::= COLON (ATOM_FRAGMENT | quote)
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                In the YECC grammar, atoms can be treated as terminals, meaning they are a single token
                                from the tokenizer because the interpolation for quoted atoms is wrapped in the
                                tokenize for atom.
                            </p>
                            <p>
                                For the Grammar Kit BNF, atoms have to be a composite because the JFlex lexer doesn't
                                backtrack, so any quoted atom just shows up as a quote with a COLON in front.
                            </p>
                        </aside>
                    </section>
                    <section id="atoms-v0.1.2">
                        <h1>v0.1.2</h1>
                        <table>
                            <thead>
                            <tr>
								<th rowspan="2">Date</th>
								<th colspan="2">Days</th>
								<th colspan="2">Commits</th>
								<th>Version</th>
							</tr>
							<tr>
								<th>Delta</th>
								<th>Total</th>
								<th>Delta</th>
								<th>Total</th>
								<th>Commits/Day</th>
							</tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>2014&#8209;09&#8209;13</td>
								<td>5</td>
								<td>60</td>
								<td>12</td>
								<td>123</td>
								<td>2.50</td>
                            </tr>
                            </tbody>
                        </table>
                        <ul>
                            <li>
                                <p>Enhancements</p>
                                <ul>
                                    <li>
                                        <p>Atoms with highlighting</p>
                                        <ul>
                                            <li>
                                                Atom with double or single quotes to allow interpolation.  Double quotes are highlighted as 'String'
                                                while single quotes are highlighted as 'Char List'.  This may be changed in the future.
                                            </li>
                                            <li>Literal atoms highlighted as 'Atom'.</li>
                                            <li>Operator atoms highlighted as 'Atom'.</li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>
                        </ul>
                    </section>
                </section>
                <section class="stack">
                    <section id="matched-expressions">
                        <h1>Matched Expressions</h1>
                        <ul>
                            <li>
                                <a href="#/matched-expressions-call-syntaxes">Call Syntaxes</a>
                            </li>
                            <li>
                                <a href="#/matched-expressions-yecc-associativity-and-precedence">YECC Associativity and Precedence</a>
                            </li>
                            <li>
                                <a href="#/matched-expressions-grammar-kit-precedence">Grammar Kit Precedence</a>
                            </li>
                            <li>
								<a href="#/matched-expressions-grammar-kit-associativity">Grammar Kit Associativity</a>
                            </li>
							<li>
								<a href="#/matched-expressions-grammars">Grammars</a>
							</li>
							<li>
								<a href="#/matched-expressions-parsing-direction">Parsing Direction</a>
							</li>
							<li>
								<a href="#/matched-expressions-yecc-vs-grammar-kit-generated-code">YECC vs Grammar Kit Generated Code</a>
							</li>
							<li>
								<p>Pratt Parsing</p>
								<ul>
									<li>
										<a href="#/matched-expressions-pratt-parsing-head">Head</a>
									</li>
									<li>
										<a href="#/matched-expressions-pratt-parsing-tail">Tail</a>
									</li>
								</ul>
							</li>
							<li>
								<a href="#/matched-expressions-associativity">Associativity</a>
							</li>
							<li>
								<a href="#/matched-expressions-v0.2.0">v0.2.0</a>
							</li>
                        </ul>
                    </section>
                    <section id="matched-expressions-call-syntaxes">
                        <h1>Call Syntaxes</h1>
                        <table>
                            <thead>
                            <tr>
                                <th>
                                    <code>elixir_parser.yrl</code>
                                </th>
                                <th>
                                    <code>Elixir.bnf</code>
                                </th>
                                <th>Description</th>
                            </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>
                                    <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_parser.yrl#L113-L122">
                                        <code>matched_expr</code>
                                    </a>
                                </td>
                                <td>
                                    <a href="https://github.com/KronicDeth/intellij-elixir/blob/0f8e974c4ec965c2f06653c8bddce7ddd3e80335/src/org/elixir_lang/Elixir.bnf#L191-L211">
                                        <code>matchedExpression</code>
                                    </a>
                                </td>
                                <td>
                                    With Parentheses*
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_parser.yrl#L124-L125">
                                        <code>no_parens_expr</code>
                                    </a>
                                </td>
                                <td>
                                    <a href="https://github.com/KronicDeth/intellij-elixir/blob/v1.0.0/src/org/elixir_lang/Elixir.bnf#L248-L259">
                                        <code>unqualifiedNoParenthesesManyArgumentsCall</code>
                                    </a>
                                </td>
                                <td>
                                    Without Parentheses
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_parser.yrl#L127-L133">
                                        <code>unmatched_expr</code>
                                    </a>
                                </td>
                                <td>
                                    <a href="https://github.com/KronicDeth/intellij-elixir/blob/v1.0.0/src/org/elixir_lang/Elixir.bnf#L2335-L2370">
                                        <code>unmatchedExpression</code>
                                    </a>
                                </td>
                                <td>
                                    With Do Block
                                </td>
                            </tr>
                            </tbody>
                        </table>
                        <aside class="notes">
                            <p>
                                Elixir parser dot yurl (<code>elixir_parser.yrl</code>) explains that there are 3 call
                                syntaxes in Elixir: matched, no parentheses, and unmatched.
                            </p>
                            <p>
                                Matched also implies parentheses, except for one argument no parentheses calls because
                                they can be chained together, which looks a lot like Haskell.
                            </p>
                        </aside>
                    </section>
                    <section id="matched-expressions-yecc-associativity-and-precedence">
                        <h1>YECC associativity and precedence</h1>
                        <figure>
                            <figcaption>
                                <a href="https://github.com/elixir-lang/elixir/blob/v0.14.3/lib/elixir/src/elixir_parser.yrl#L44-L71">
                                    <code>lib/elixir/src/elixir_parser.yrl</code>
                                </a>
                            </figcaption>
                            <pre><code class="stretch" data-trim style="font-size: 175%; line-height: 100%">
%% Changes in ops and precedence should be reflected on lib/elixir/lib/macro.ex
%% Note though the operator => in practice has lower precedence than all others,
%% its entry in the table is only to support the %{user | foo => bar} syntax.
Left       5 do.
Right     10 stab_op_eol.     %% ->
Left      20 ','.
Nonassoc  30 capture_op_eol.  %% &
Left      40 in_match_op_eol. %% <-, \\ (allowed in matches along =)
Right     50 when_op_eol.     %% when
Right     60 type_op_eol.     %% ::
Right     70 pipe_op_eol.     %% |
Right     80 assoc_op_eol.    %% =>
Right     90 match_op_eol.    %% =
Left     130 or_op_eol.       %% ||, |||, or, xor
Left     140 and_op_eol.      %% &&, &&&, and
Left     150 comp_op_eol.     %% ==, !=, =~, ===, !==
Left     160 rel_op_eol.      %% <, >, <=, >=
Left     170 arrow_op_eol.    %% < (op), (op) > (e.g |>, <<<, >>>)
Left     180 in_op_eol.       %% in
Right    200 two_op_eol.      %% ++, --, .., <>
Left     210 add_op_eol.      %% + (op), - (op)
Left     220 mult_op_eol.     %% * (op), / (op)
Left     250 hat_op_eol.      %% ^ (op) (e.g ^^^)
Nonassoc 300 unary_op_eol.    %% +, -, !, ^, not, ~~~
Left     310 dot_call_op.
Left     310 dot_op.          %% .
Nonassoc 320 at_op_eol.       %% @
Nonassoc 330 dot_identifier.
                            </code></pre>
                        </figure>
                        <aside class="notes">
                            <p>
                                The YECC format has a section for declaring both the associativity and precedence of
                                operators.  The operator table doesn't completely reflect the precedence of all operator
                                combinations because there are some precedence swaps, such as for `not in`.
                            </p>
							<p>
								<code>Nonassoc</code> is used for non-binary, prefix operators that don't have
								associativity rules.
							</p>
							<p>
								Higher precedence operators (with greater numbers) in the table can act as arguments
								to the lower precedence operators, so and operators like double ampersand
								(<code>&&</code>) take comparison operation using comparison operators like double
								equals (<code>==</code>) at arguments.
							</p>
                        </aside>
                    </section>
                    <section id="matched-expressions-grammar-kit-precedence">
						<h1>Grammar Kit Precedence</h1>
						<figure>
							<figcaption>
								<a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.2.0/src/org/elixir_lang/Elixir.bnf#L191-L211">
									<code>src/org/elixir_lang/Elixir.bnf</code>
								</a>
							</figcaption>
							<pre><code class="stretch" data-trim style="font-size: 230%; line-height: 100%">
matchedExpression ::= matchedExpressionCaptureOperation |
                      matchedExpressionInMatchOperation |
                      matchedExpressionWhenOperation |
                      matchedExpressionTypeOperation |
                      matchedExpressionPipeOperation |
                      matchedExpressionMatchOperation |
                      matchedExpressionOrOperation |
                      matchedExpressionAndOperation |
                      matchedExpressionComparisonOperation |
                      matchedExpressionRelationalOperation |
                      matchedExpressionArrowOperation |
                      matchedExpressionInOperation |
                      matchedExpressionTwoOperation |
                      matchedExpressionAdditionOperation |
                      matchedExpressionMultiplicationOperation |
                      matchedExpressionHatOperation |
                      matchedExpressionUnaryOperation |
                      matchedExpressionDotOperation |
                      matchedExpressionAtOperation |
                      identifierExpression |
                      accessExpression
							</code></pre>
						</figure>
                        <aside class="notes">
                            <p>
                                There isn't a unified associativity and precedence table for Grammar Kit's BNF.
                                Instead, the precedence is order of choice in parent expression, which is also the
								argument expression.
                            </p>
							<p>
								Instead of stating the precedence of the operators as is done in YECC, the precedence
								of operations using those operator is done in Grammar Kit.
							</p>
                        </aside>
                    </section>
					<section id="matched-expressions-grammar-kit-associativity">
						<h1>Grammar Kit Associativity</h1>
						<figure>
							<figcaption>
								<a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.2.0/src/org/elixir_lang/Elixir.bnf#L214-L232">
									<code>src/org/elixir/Elixir.bnf</code>
								</a>
							</figcaption>
							<pre><code class="stretch" data-trim style="font-size: 115%; line-height: 100%">
matchedExpressionAdditionOperation ::= matchedExpression DUAL_OPERATOR EOL* matchedExpression
matchedExpressionAndOperation ::= matchedExpression EOL* AND_OPERATOR EOL* matchedExpression
matchedExpressionArrowOperation ::= matchedExpression EOL* ARROW_OPERATOR EOL* matchedExpression
matchedExpressionAtOperation ::= AT_OPERATOR EOL* matchedExpression
matchedExpressionCaptureOperation ::= CAPTURE_OPERATOR EOL* matchedExpression
matchedExpressionComparisonOperation ::= matchedExpression EOL* COMPARISON_OPERATOR EOL* matchedExpression
matchedExpressionDotOperation ::= matchedExpression EOL* DOT_OPERATOR EOL* matchedExpression
matchedExpressionHatOperation ::= matchedExpression EOL* HAT_OPERATOR EOL* matchedExpression
matchedExpressionInMatchOperation ::= matchedExpression EOL* IN_MATCH_OPERATOR EOL* matchedExpression
matchedExpressionInOperation ::= matchedExpression EOL* IN_OPERATOR EOL* matchedExpression
matchedExpressionMatchOperation ::= matchedExpression EOL* MATCH_OPERATOR EOL* matchedExpression { rightAssociative = true }
matchedExpressionMultiplicationOperation ::= matchedExpression EOL* MULTIPLICATION_OPERATOR EOL* matchedExpression
matchedExpressionOrOperation ::= matchedExpression EOL* OR_OPERATOR EOL* matchedExpression
matchedExpressionPipeOperation ::= matchedExpression EOL* PIPE_OPERATOR EOL* matchedExpression { rightAssociative = true }
matchedExpressionRelationalOperation ::= matchedExpression EOL* RELATIONAL_OPERATOR EOL* matchedExpression
matchedExpressionTwoOperation ::= matchedExpression EOL* TWO_OPERATOR EOL* matchedExpression { rightAssociative = true }
matchedExpressionTypeOperation ::= matchedExpression EOL* TYPE_OPERATOR EOL* matchedExpression { rightAssociative = true }
matchedExpressionUnaryOperation ::= (DUAL_OPERATOR | UNARY_OPERATOR) EOL* matchedExpression
matchedExpressionWhenOperation ::= matchedExpression EOL* WHEN_OPERATOR EOL* matchedExpression { rightAssociative = true }
							</code></pre>
						</figure>
						<aside class="notes">
							<p>
								So, the pattern for binary operations are matched expression
								(<code>matchedExpression</code>) on either side of the actual operator token with
								optional newlines around the operator.
							</p>
							<p>
								Left associativity is assumed by default, so right associativity is indicated with
								right associative equals true (<code>rightAssociative = true</code>) in the braces after
								the rule.
							</p>
							<p>
								You may have noticed that these rules appear to be recursive: on the previous slide,
								matched expression (<code>matchedExpression</code>) was defined as the ordered choice
								of all the operations on this on this slide, but all the operations use matched
								expression (<code>matchedExpression</code>) as both the left and right argument, so
								why doesn't parser go into an infinite loop on the first binary rule, matched
								expression in match operation (<code>matchedExpressionInMatchOperation</code>)?
							</p>
							<p>
								There is no loop because Grammar Kit has some extensions that allow it to detect this
								pattern of rules.
							</p>
						</aside>
					</section>
					<section id="matched-expressions-grammars">
						<h1>Grammars</h1>
						<table>
							<thead>
							<tr>
								<th></th>
								<th>Look-ahead, Left-to-Right, Rightmost deriviation (LALR)</th>
								<th>Parsing Expression Grammar</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<th>Inventor</th>
								<td>Frank DeRemer</td>
								<td>Bryan Ford</td>
							</tr>
							<tr>
								<th>Invented</th>
								<td>1969</td>
								<td>2004</td>
							</tr>
							<tr>
								<th>Terminal symbols</th>
								<td>&#10003;</td>
								<td>&#10003;</td>
							</tr>
							<tr>
								<th>Nonterminal rules</th>
								<td>&#10003;</td>
								<td>&#10003;</td>
							</tr>
							<tr>
								<th>Empty string</th>
								<td>&#10003;</td>
								<td>&#10003;</td>
							</tr>
							<tr>
								<th>Sequence</th>
								<td>&#10003;</td>
								<td>&#10003;</td>
							</tr>
							<tr>
								<th>Choice</th>
								<td>Ambiguous</td>
								<td>Ordered</td>
							</tr>
							<tr>
								<th>Zero-or-more</th>
								<td>
									<span style="color: red">&#10060;</span>
								</td>
								<td>
									<code>*</code>
								</td>
							</tr>
							<tr>
								<th>One-or-more</th>
								<td>
									<span style="color: red">&#10060;</span>
								</td>
								<td>
									<code>+</code>
								</td>
							</tr>
							<tr>
								<th>Optional</th>
								<td>
									<span style="color: red">&#10060;</span>
								</td>
								<td>
									<code>?</code>
								</td>
							</tr>
							<tr>
								<th>Positive Look-ahead</th>
								<td>
									<span style="color: red">&#10060;</span>
								</td>
								<td>
									<code>&</code>
								</td>
							</tr>
							<tr>
								<th>Negative Look-ahead</th>
								<td>
									<span style="color: red">&#10060;</span>
								</td>
								<td>
									<code>!</code>
								</td>
							</tr>
							<tr>
								<th>Derivation</th>
								<td>Rightmost</td>
								<td>Leftmost</td>
							</tr>
							<tr>
								<th>Left-Recursion</th>
								<td>Favored</td>
								<td>Infinite Loop</td>
							</tr>
							<tr>
								<th>Right-Recursion</th>
								<td>Unfavored</td>
								<td>Favored</td>
							</tr>
							<tr>
								<th>Direction</th>
								<td>Bottom-up</td>
								<td>Top-down</td>
							</tr>
							</tbody>
						</table>
						<aside class="notes">
							<p>
								YECC is a LALR, or look-ahead, left-to-right, rightmost derivation parser generator.
								Grammar Kit is a Parsing Expression Grammar parser generator.
							</p>
							<p>
								LALR parsers were invented back in 1969, but Parsing Expression Grammar weren't invented
								until 2004, so they may have come out after some of us were in college.
							</p>
							<p>
								LALR grammars don't have syntax for zero-or-more, one-or-more, or optional, instead they
								have to be constructed with recursive rules or rule clauses involving empty strings,
								so the grammar has to be more verbose.
							</p>
							<p>
								LALR has look-ahead in its name, but the grammar itself has no control of how far to
								look-ahead.  Instead, it's hard-coded to be one token.  In parsing expression grammars
								any rule can be put after ampersand (<code>&</code>) to do a positive look-ahead or
								after exclamation point (<code>!</code>) to do negative look-ahead.
							</p>
							<p>
								This look-ahead being rule based instead of token based means it is potentially
								infinite, but that also means that performance in both memory and speed can be worse
								if the look-ahead is chosen poorly.  For LALR, the look-ahead is automatically one
								token and the best rule can be chosen as the match, but the rule order and look-ahead
								is under control of the grammar for Parsing Expression Grammars.
							</p>
						</aside>
					</section>
					<section id="matched-expressions-parsing-direction">
						<h1>Parsing Direction</h1>
						<table>
							<thead>
							<tr>
								<th></th>
								<th>
									Top-Down / Leftmost Derivation
								</th>
								<th>
									Bottom-Up / Rightmost Derivation
								</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<th>First Symbol</th>
								<td>Root</td>
								<td>Tokens</td>
							</tr>
							<tr>
								<th>Building</th>
								<th>Choses children for current rule</th>
								<td>Combines tokens/rules</td>
							</tr>
							<tr>
								<th>Last Symbol</th>
								<th>Tokens</th>
								<th>Root</th>
							</tr>
							<tr>
								<th>Strength</th>
								<td>Easier to write</td>
								<td>Faster to run</td>
							</tr>
							</tbody>
						</table>
						<aside class="notes">
							<p>
								Top-down parsing can be thought of using functions to try to match the beginning of the
								input.  Inside each function, the child rules are called to see if they match.  If
								all the child rules matches recursively, then top-down finds a match.
							</p>
							<p>
								Bottom-up parsing starts with the leaf tokens and tries to reduce the right-most branches
								into parent, and then ancestor nodes until getting to a root node that matches the
								top-down parsing's entry point.
							</p>
							<p>
								Bottom-up parser have the benefit of usually having linear bound on their parsing time
								relative to the input size while top-down parsing can involve a lot of backtrack, but
								the generated code is more human readable and debuggable.
							</p>
						</aside>
					</section>
					<section id="matched-expressions-yecc-vs-grammar-kit-generated-code">
						<h1>YECC vs Grammar Kit Generated Code</h1>
						<table class="stretch">
							<thead>
							<tr>
								<th>YECC</th>
								<th>Grammar Kit</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<td>
									<figure>
										<figcaption>
											<code>lib/elixir/src/elixir_parser.erl</code>
										</figcaption>
										<pre><code class="erlang stretch" data-trim>
yeccpars2_6(S, '(', Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 40, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, ')', Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 288, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, ';', Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 289, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, '[', Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 43, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, kw_identifier, Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 87, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, kw_identifier_safe, Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 88, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, kw_identifier_unsafe, Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 89, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, number, Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 60, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, stab_op, Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 290, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, '{', Ss, Stack, T, Ts, Tzr) ->
 yeccpars1(S, 66, Ss, Stack, T, Ts, Tzr);
yeccpars2_6(S, Cat, Ss, Stack, T, Ts, Tzr) ->
 yeccpars2_cont_2(S, Cat, Ss, Stack, T, Ts, Tzr).
										</code></pre>
									</figure>
								</td>
								<td>
									<figure>
										<figcaption>
											<a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.2.0/gen/org/elixir_lang/parser/ElixirParser.java#L214-L235">
												<code>gen/org/elixir_lang/parser/ElixirParser.java</code>
											</a>
										</figcaption>
										<pre><code class="java stretch" data-trim style="font-size: 140%; line-height: 100%">
public class ElixirParser implements PsiParser {
  // COLON (ATOM_FRAGMENT | quote)
  public static boolean atom(PsiBuilder b, int l) {
    if (!recursion_guard_(b, l, "atom")) return false;
    if (!nextTokenIs(b, COLON)) return false;
    boolean r;
    Marker m = enter_section_(b);
    r = consumeToken(b, COLON);
    r = r && atom_1(b, l + 1);
    exit_section_(b, m, ATOM, r);
    return r;
  }

  // ATOM_FRAGMENT | quote
  private static boolean atom_1(PsiBuilder b, int l) {
    if (!recursion_guard_(b, l, "atom_1")) return false;
    boolean r;
    Marker m = enter_section_(b);
    r = consumeToken(b, ATOM_FRAGMENT);
    if (!r) r = quote(b, l + 1);
    exit_section_(b, m, null, r);
    return r;
  }
}
										</code></pre>
									</figure>
								</td>
							</tr>
							</tbody>
						</table>
						<aside class="notes">
							<p>
								YECC's generated code is very well optimized, handling individual characters or
								atoms as tokens, while Grammar Kit's code is less optimized and more like if you
								as a developer wrote the match functions.  Grammar Kit's methods match the rule
								names while the yecc parse functions use number offsets.
							</p>
							<p>
								This made debugging the generate parsers very easy, except that just like YECC's code,
								you can't ask for the in progress AST.
							</p>
						</aside>
					</section>
					<section id="matched-expressions-pratt-parsing-head">
						<h1>Pratt Parsing - Head</h1>
						<figure>
							<a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.2.0/gen/org/elixir_lang/parser/ElixirParser.java#L1804-L1842">
								<code>gen/org/elixir_lang/parser/ElixirParser.java</code>
							</a>
							<pre><code class="java stretch" data-trim style="font-size: 125%; line-height: 100%">
public class ElixirParser implements PsiParser {
  /* ********************************************************** */
  // Expression root: matchedExpression
  // Operator priority table:
  // 0: PREFIX(matchedExpressionCaptureOperation)
  // 1: BINARY(matchedExpressionInMatchOperation)
  // 2: BINARY(matchedExpressionWhenOperation)
  // 3: BINARY(matchedExpressionTypeOperation)
  // 4: BINARY(matchedExpressionPipeOperation)
  // 5: BINARY(matchedExpressionMatchOperation)
  // 6: BINARY(matchedExpressionOrOperation)
  // 7: BINARY(matchedExpressionAndOperation)
  // 8: BINARY(matchedExpressionComparisonOperation)
  // 9: BINARY(matchedExpressionRelationalOperation)
  // 10: BINARY(matchedExpressionArrowOperation)
  // 11: BINARY(matchedExpressionInOperation)
  // 12: BINARY(matchedExpressionTwoOperation)
  // 13: BINARY(matchedExpressionAdditionOperation)
  // 14: BINARY(matchedExpressionMultiplicationOperation)
  // 15: BINARY(matchedExpressionHatOperation)
  // 16: PREFIX(matchedExpressionUnaryOperation)
  // 17: BINARY(matchedExpressionDotOperation)
  // 18: PREFIX(matchedExpressionAtOperation)
  // 19: ATOM(identifierExpression)
  // 20: ATOM(accessExpression)
  public static boolean matchedExpression(PsiBuilder b, int l, int g) {
    if (!recursion_guard_(b, l, "matchedExpression")) return false;
    addVariant(b, "&lt;matched expression&gt;");
    boolean r, p;
    Marker m = enter_section_(b, l, _NONE_, "&lt;matched expression&gt;");
    r = matchedExpressionCaptureOperation(b, l + 1);
    if (!r) r = matchedExpressionUnaryOperation(b, l + 1);
    if (!r) r = matchedExpressionAtOperation(b, l + 1);
    if (!r) r = identifierExpression(b, l + 1);
    if (!r) r = accessExpression(b, l + 1);
    p = r;
    r = r && matchedExpression_0(b, l + 1, g);
    exit_section_(b, l, m, null, r, p, null);
    return r || p;
  }
}
							</code></pre>
						</figure>
						<aside class="notes">
							<p>
								The generated code I showed and the rules for parsing expression grammars say that left
								recursion is impossible, so how am I allowed to have matched expression
								(<code>matchedExpression</code>) as the left-most rule in a rule that's part of matched
								expression (<code>matchedExpression</code>) itself?
							</p>
							<p>
								Pratt parsing is an extension to recursive-descent parsers, which include parsing
								expression grammars, that allows for optimization for parsing operators by noticing
								patterns in how humans write binary operators to eliminate left-recursion.
							</p>
							<p>
								The optimization involves noticing that eventually all operation rules get to
								rules that aren't left-recursive or that are tokens, so the parser generator itself
								can do the left-recursion elimination by looking for those non-left-recursive rules
								first, then try to consume an operator, then do it all over again, but keep track
								of the precedence of the operator.
							</p>
							<p>
								Here, you can see that the prefix operations, matched expression unary operation
								(<code>matchedExpressionUnaryOperation</code>) and matched expression at operation
								(<code>matchedexpressionAtOperation</code>), can be checked for because they consume
								an operator token first and so aren't left-recursive.
							</p>
							<p>
								Likewise, identifier expression (<code>identifierExpression</code>) and access
								expression (<code>accessExpression</code>) are atoms, so they don't include
								matched expression (<code>matchedExpression</code>) at all and so can be used to
								consume input immediately.
							</p>
							<p>
								Once some input is consumed, matched expression (<code>matchedExpression</code>)
								goes into matched expression underscore 0 (<code>matchedExpression_0</code>).  For
								user written rules the underscore number system is unused for anonymous groups in
								parentheses, but here's it's meant to indicate that the parser is checking the tail
								of all the matched expression (<code>matchedExpression</code>) rules.
							</p>
						</aside>
					</section>
					<section id="matched-expressions-pratt-parsing-tail">
						<h1>Pratt Parsing - Tail</h1>
						<figure>
							<figcaption>
								<a href="https://github.com/KronicDeth/intellij-elixir/blob/v0.2.0/gen/org/elixir_lang/parser/ElixirParser.java#L1844-L1919">
									<code>gen/org/elixir_lang/parser/ElixirParser.java</code>
								</a>
							</figcaption>
							<pre><code class="java stretch" data-trim style="font-size: 130%; line-height: 100%">
public class ElixirParser implements PsiParser {
 public static boolean matchedExpression_0(PsiBuilder b, int l, int g) {
    if (!recursion_guard_(b, l, "matchedExpression_0")) return false;
    boolean r = true;
    while (true) {
      Marker m = enter_section_(b, l, _LEFT_, null);
      if (g &lt; 1 && matchedExpressionInMatchOperation_0(b, l + 1)) {
        r = matchedExpression(b, l, 1);
        exit_section_(b, l, m, MATCHED_EXPRESSION_IN_MATCH_OPERATION, r, true, null);
      }
      else if (g &lt; 2 && matchedExpressionWhenOperation_0(b, l + 1)) {
        r = matchedExpression(b, l, 1);
        exit_section_(b, l, m, MATCHED_EXPRESSION_WHEN_OPERATION, r, true, null);
      }
      else if (g &lt; 3 && matchedExpressionTypeOperation_0(b, l + 1)) {
        r = matchedExpression(b, l, 2);
        exit_section_(b, l, m, MATCHED_EXPRESSION_TYPE_OPERATION, r, true, null);
      }
      else if (g &lt; 4 && matchedExpressionPipeOperation_0(b, l + 1)) {
        r = matchedExpression(b, l, 3);
        exit_section_(b, l, m, MATCHED_EXPRESSION_PIPE_OPERATION, r, true, null);
      }
      else if (g &lt; 5 && matchedExpressionMatchOperation_0(b, l + 1)) {
        r = matchedExpression(b, l, 4);
        exit_section_(b, l, m, MATCHED_EXPRESSION_MATCH_OPERATION, r, true, null);
      }
      else if (g < 6 && matchedExpressionOrOperation_0(b, l + 1)) {
        r = matchedExpression(b, l, 6);
        exit_section_(b, l, m, MATCHED_EXPRESSION_OR_OPERATION, r, true, null);
      }
      // ...
      else {
        exit_section_(b, l, m, null, false, false, null);
        break;
      }
    }
    return r;
  }								
}
							</code></pre>
						</figure>
						<aside class="notes">
							<p>
								The pattern used in matched expression (<code>matchedExpression</code>) and matced
								expression zero (<code>matchedExpression_0</code>) is based on Douglas Crockford's
								Top Down Operator Precedence implementation in Javascript.
							</p>
							<p>
								<code>g</code> is the right-binding power of the currently matched operator.  Only
								operators with a stronger binding power (because they are higher precedence) can
								be matched when recursing, but if no stronger rule is matched on the recursive
								call to matched expression (<code>matchedExpression</code>), then the while loop
								allows for matching operators of equal right-binding power.
							</p>
							<p>
								The left-associative, in match at the beginning and or at the end of the excerpt all
								follow the pattern of recursive call to matched expression
								(<code>matchedExpression</code>) with <code>g</code> one greater than the max for the
								current operator (so g less than 1 and 1 is passed; g less than 6 and 6 is passed).
								This ensures that adjacent left operators at the same level are matched by the while
								loop, which are then properly left-nested by the underscore left
								underscore (<code>_LEFT_</code>) directive in the <code>m</code> marker at the top of
								while loop.
							</p>
							<p>
								The underscore left underscore (<code>_LEFT_</code>) directive is similar how the
								pipelines are rearranged in Elixir.
							</p>
							<p>
								For right-associative operators, like when, type, pipe, and match, the if clauses
								recursively calls matched expression (<code>matchedExpression</code> with
								<code>g</code> that can match the current operator, which means adjacent
								right-associative operators or any higher precedence operator is properly nested at a
								lower level.  Since the parser is left-most derivation, any nesting occurs on the
								right-end, so nesting gets the proper right-associative behavior.
							</p>
						</aside>
					</section>
					<section id="matched-expressions-associativity">
						<h1>Associativity</h1>
						<table>
							<thead>
							<tr>
								<th>Associativity</th>
								<th>Left</th>
								<th>Right</th>
							</tr>
							<tr>
								<th>Code</th>
								<td>
									<code>a or b || c</code>
								</td>
								<td>
									<code>a ++ b <> c</code>
								</td>
							</tr>
							<tr>
								<th>Nesting</th>
								<td>
									<ul>
										<li>
											<code>||</code>
											<ul>
												<li>
													<code>or</code>
													<ul>
														<li>
															<code>a</code>
														</li>
														<li>
															<code>b</code>
														</li>
													</ul>
												</li>
												<li>
													<code>c</code>
												</li>
											</ul>
										</li>
									</ul>
								</td>
								<td>
									<ul>
										<li>
											<code>++</code>
											<ul>
												<li>
													<code>a</code>
												</li>
												<li>
													<code>&lt;&gt;</code>
													<ul>
														<li>
															<code>b</code>
														</li>
														<li>
															<code>c</code>
														</li>
													</ul>
												</li>
											</ul>
										</li>
									</ul>
								</td>
							</tr>
							<tr>
								<th>Effective Parentheses</th>
								<td>
									<code>(a or b) || c</code>
								</td>
								<td>
									<code>a ++ (b <> c)</code>
								</td>
							</tr>
							<tr>
								<th>Execution Pipeline</th>
								<td>
									a |> Kernel.or(b) |> Kernel.||(c)
								</td>
								<td>
									a |> Kernel.++(b |> Kernel.<>(c))
								</td>
							</tr>
							</thead>
						</table>
						<aside class="notes">
							<p>
								Instead of having to visual that in your head, let's see a nested example for
								left- and right-associative operators.
							</p>
							<p>
								I'm using the or operators, the word <code>or</code> and double pipes (<code>||</code>)
								for the left-associative operator because they're easy to distingish.  Similarly,
								I'm using the two operators, double plus (<code>++</code>) and diamond
								(<code>&lt;&gt;</code>), for the right-associative operator.  Remember, the two
								operators in each example are of the same precedence, so it's just the associativity
								controlling the nesting.
							</p>
							<p>
								For left-associative, the left-most operator becomes the root of the tree with
								the right operand executing first, so it looks like the operators are in the wrong
								order, but if you rearrange the nesting to pipeline order it makes sense.
							</p>
							<p>
								For right-associative, reading the tree in order, it looks like it matches, the order
								of the code, but when you change it to pipeline order you can see the the second
								operation must actually complete at the same time as the first argument.
							</p>
						</aside>
					</section>
                    <section id="matched-expressions-v0.2.0">
                        <h1>v0.1.3 and v0.2.0</h1>
                        <table>
                            <thead>
                            <tr>
								<th rowspan="2">Date</th>
								<th colspan="2">Days</th>
								<th colspan="2">Commits</th>
								<th>Version</th>
							</tr>
							<tr>
								<th>Delta</th>
								<th>Total</th>
								<th>Delta</th>
								<th>Total</th>
								<th>Commits/Day</th>
							</tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>2014&#8209;11&#8209;30</td>
								<td>66</td>
								<td>126</td>
								<td>250</td>
								<td>373</td>
								<td>3.79</td>
                            </tr>
                            </tbody>
                        </table>
                        <ul style="font-size: 35%">
                            <li>
                                <p>Enhancements</p>
                                <ul>
                                    <li>All valid escape sequences (<code>\&lt;character&gt;</code>, <code>\x&lt;hexadecimal&gt;</code>, <code>\x{&lt;hexadecimal&gt;}</code>,) are recognized.</li>
                                    <li>Support for creation of Elixir modules</li>
                                    <li>Use pygments' elixir_example.ex supplied by Alexei Sholik for Color Settings Page.<li>
                                    <li><code>?</code> before any character or valid escape sequence will be recognized as a character token.</li>
                                    <li><code>;</code> is recognized as EOL. <code>\r\n</code> and <code>\n</code> style EOL can be escaped with <code>\</code> and will be treated as whitespace.</li>
                                    <li>Operator arity, associativity, and precedence</li>
                                    <li>Decimal integers and floats</li>
                                    <li>Identifiers (variable, function, and macro names)</li>
                                    <li><code>...</code> identifier</li>
                                    <li>Aliases (module names)</li>
                                    <li>Keyword Identifiers</li>
                                    <li>Empty Parentheses</li>
                                    <li>In Operator</li>
                                    <li>Dot Operator</li>
                                    <li>Keyword Lists</li>
                                    <li>Matched Expressions</li>
                                    <li>Regular Keywords (<code>end</code>, <code>false</code>, <code>fn</code>, <code>nil</code>, and <code>true</code>)
                                    <li>
                                        <p>New attributes for parts of numbers on Color Settings Page</p>
                                        <ul>
                                            <li>Binary, Decimal, Hexadecimal, and Octal Digits</li>
                                            <li>Decimal Exponent, Mark, and Separator</li>
                                            <li>
                                                <p>Invalid Binary, Decimal, Hexadecimal, and Octal Digits</p>
                                                <ul>
                                                    <li>2-9, A-Z, and a-z will be parsed as invalid binary digits</li>
                                                    <li>8-9, A-Z, and a-z will be parsed as invalid octal digits</li>
                                                    <li>G-Z and g-z will be parsed as invalid hexadecimal digits</li>
                                                </ul>
                                            </li>
                                            <li>
                                                <p>Non-Decimal Base Prefix</p>
                                                <ul>
                                                    <li>Any letter other than b, o, or x, in either case, will be recognized as an invalid whole number base</li>
                                                </ul>
                                            </li>
                                            <li>Obsolete Non-Decimal Base Prefix (<code>B</code> for binary and <code>X</code> for hexadecimal)</li>
                                        </ul>
                                    </li>
                                    <li>Any digit, 0-9, A-Z, or a-z will be parsed as invalid for invalid whole number based numbers</li>
                                    <li>Recovery for non-decimal whole numbers if the prefix is given, but no digits are given</li>

                                </ul>
                            </li>
                            <li>
                                <p>Bug Fixes</p>
                                <ul>
									<li>Blank lines are properly parsed as whitespace instead of bad characters.</li>
									<li>EOL is parsed as bad character in sigil name (after `~`) instead of causing the lexer to fail to match, which raised exceptions in Event Log.</li>
                                    <li>Sigil terminator escapes are recognized, so that sigils are no longer prematurely terminated.</li>
                                    <li>Comments do not consume EOL, so trailing comments don't cause error parsing expression on following line.</li>
                                    <li>Sigil modifiers now work on groups in addition to heredocs.</li>
                                    <li><code>;</code> is separate from <code>EOL</code> and either or both can separate expressions, but only <code>EOL</code> can separate operators and operands for operations</li>
                                </ul>
                            </li>
                            <li>
                                <p>Incompatible Changes</p>
                                <ul>
                                    <li>Recovery for non-decimal whole numbers if the prefix is given, but no digits are given</li>
                                </ul>
                            </li>
                            <aside class="notes">
                                <p>
                                    Version zero dot one dot four (v0.1.4) wasn't released, so the next release, zero
                                    dot two dot zero (v0.2.0) didn't come until one third of the way through the first
                                    year of the project, on day 126.
                                </p>
                                <p>
                                    It contained a plethora of changes and was the first time useful code, such as
                                    mathematical operations could be recognized by the parser.
                                </p>
								<p>
									But, as you can gather from the previous slides a lot of that time was me learning
									the difference between YECC's LALR and Grammar Kit's Parsing Expression Grammar
									with Pratt Parsing.
								</p>
                            </aside>
                        </ul>
                    </section>
                </section>
				<section id="bibliography">
                    <h1>Bibliography</h1>
					<ul>
						<li>
							<a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_Form">
								Backus-Naur Form
							</a>
						</li>
                        <li>
                            <a href="https://en.wikipedia.org/wiki/Nondeterministic_finite_automaton">
                                Nondeterministic Finite Automaton
                            </a>
                        </li>
                        <li>
                            <a href="https://en.wikipedia.org/wiki/Powerset_construction">
                                Powerset Construction
                            </a>
                        </li>
                        <li>
                            <a href="https://en.wikipedia.org/wiki/Deterministic_finite_automaton">
                                Deterministic Finite Automaton
                            </a>
                        </li>
						<li>
							Automata, Computability, and Complexity: Theory and Applications by Elaine Rich
						</li>
						<li>
							<a href="https://en.wikipedia.org/wiki/Recursive_language">
								Decidable Language
							</a>
						</li>
						<li>
							<a href="http://javascript.crockford.com/tdop/tdop.html">
								Douglas Crockford's Top Down Operator Precedence
							</a>
						</li>
					</ul>
				</section>
			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				center: true,
				controls: true,
				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				],
				height: 1280,
				history: true,
				progress: true,
				// Slide number formatting can be configured using these variables:
				//  h: current slide's horizontal index
				//  v: current slide's vertical index
				//  c: current slide index (flattened)
				//  t: total number of slides (flattened)
				slideNumber: 'c / t',
				transition: 'slide', // none/fade/slide/convex/concave/zoom
				width: 2048
			});

		</script>

	</body>
</html>
